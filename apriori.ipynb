{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  F  G  H\n",
       "0  1  1  0  1  1  0  1  0\n",
       "1  0  0  0  0  1  0  1  0\n",
       "2  0  1  0  0  0  1  1  0\n",
       "3  1  0  0  0  1  0  0  0\n",
       "4  0  1  1  1  1  0  0  1\n",
       "5  0  0  1  0  1  0  1  1\n",
       "6  1  0  1  0  0  0  1  1\n",
       "7  1  1  1  1  1  1  1  0\n",
       "8  1  1  0  0  1  1  0  1\n",
       "9  0  0  0  1  1  0  0  1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# Make dummy data\n",
    "data = pd.DataFrame(np.random.randint(0, 2, size=(10, 8)), columns=list('ABCDEFGH'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  F  G  H\n",
       "0  5  5  6  6  2  7  4  5\n",
       "1  5  5  4  4  8  3  6  5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of 0s and 1s in each column\n",
    "# The number of 1s is the number of times each item appears\n",
    "value_counts = data.apply(pd.value_counts)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts['A'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lecture notes explanation of the Apriori Algorithm, we have 4 steps to do.\n",
    "1. Candidate Generation\n",
    "2. Candidate Pruning\n",
    "3. Support Counting\n",
    "4. Candidate Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for 1 and 2 itemset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the min support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined dictionary of frequent itemsets\n",
    "combined_freq_itemsets = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate F1 (frequent 1-itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 5, 'B': 5, 'C': 4, 'D': 4, 'E': 8, 'G': 6, 'H': 5}\n",
      "{('A',): 5, ('B',): 5, ('C',): 4, ('D',): 4, ('E',): 8, ('G',): 6, ('H',): 5}\n"
     ]
    }
   ],
   "source": [
    "# Get the frequent itemsets with count greater than or equal to min_support\n",
    "columns = data.columns\n",
    "frequent_itemsets = {}\n",
    "for column in columns:\n",
    "    # Append the itemset and its count to the dictionary if the count is greater than or equal to min_support\n",
    "    if value_counts[column][1] >= min_support:\n",
    "        frequent_itemsets[column] = value_counts[column][1]\n",
    "        # frequent_itemsets.append((column, value_counts[column][1]))\n",
    "        # data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "print(frequent_itemsets)\n",
    "\n",
    "dummy_dict = frequent_itemsets.copy()\n",
    "for key, item in dummy_dict.copy().items():\n",
    "    dummy_dict[(tuple(key))] = dummy_dict.pop(key)\n",
    "print(dummy_dict)\n",
    "    \n",
    "combined_freq_itemsets.update(dummy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('A', 'B'),\n",
       "  ('A', 'C'),\n",
       "  ('A', 'D'),\n",
       "  ('A', 'E'),\n",
       "  ('A', 'G'),\n",
       "  ('A', 'H'),\n",
       "  ('B', 'C'),\n",
       "  ('B', 'D'),\n",
       "  ('B', 'E'),\n",
       "  ('B', 'G'),\n",
       "  ('B', 'H'),\n",
       "  ('C', 'D'),\n",
       "  ('C', 'E'),\n",
       "  ('C', 'G'),\n",
       "  ('C', 'H'),\n",
       "  ('D', 'E'),\n",
       "  ('D', 'G'),\n",
       "  ('D', 'H'),\n",
       "  ('E', 'G'),\n",
       "  ('E', 'H'),\n",
       "  ('G', 'H')]]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate all possible combinations of frequent itemsets with k+1 items\n",
    "combinations = []\n",
    "k = 1\n",
    "combinations.append(list(itertools.combinations(frequent_itemsets.keys(), k+1)))\n",
    "\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Candidate Pruning (do not need to prune for 2 itemset as F1 items are all frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Support Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists of tuples to a list of tuples\n",
    "combinations = combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'B'): 3,\n",
       " ('A', 'C'): 2,\n",
       " ('A', 'D'): 2,\n",
       " ('A', 'E'): 4,\n",
       " ('A', 'G'): 3,\n",
       " ('A', 'H'): 2,\n",
       " ('B', 'C'): 2,\n",
       " ('B', 'D'): 3,\n",
       " ('B', 'E'): 4,\n",
       " ('B', 'G'): 3,\n",
       " ('B', 'H'): 2,\n",
       " ('C', 'D'): 2,\n",
       " ('C', 'E'): 3,\n",
       " ('C', 'G'): 3,\n",
       " ('C', 'H'): 3,\n",
       " ('D', 'E'): 4,\n",
       " ('D', 'G'): 2,\n",
       " ('D', 'H'): 2,\n",
       " ('E', 'G'): 4,\n",
       " ('E', 'H'): 4,\n",
       " ('G', 'H'): 2}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurences of each combination in the data\n",
    "combinations_count = {}\n",
    "for combination in combinations:\n",
    "    # Using groupby and size to count the number of occurences of each combination\n",
    "    # Resetting the index to get the count of each combination as a column in the dataframe\n",
    "    test = data.groupby(list(combination)).size().reset_index(name='count')\n",
    "\n",
    "    # Append the combination and its count to the dictionary\n",
    "    # The count of each combination is the last value in the count column\n",
    "    # as the last row of the dataframe is when both items are present in one transaction in the original data dataframe\n",
    "    combinations_count[combination] = test['count'].iloc[-1]\n",
    "\n",
    "# print(test)\n",
    "combinations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.index.values[-1].count(1)\n",
    "test1 = test\n",
    "count = test1['count'].iloc[-1]\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Candidate Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('A', 'E'): 4, ('B', 'E'): 4, ('D', 'E'): 4, ('E', 'G'): 4, ('E', 'H'): 4}\n"
     ]
    }
   ],
   "source": [
    "# Prune the combinations with count less than min_support\n",
    "for combination in combinations_count.copy().keys():\n",
    "    if combinations_count[combination] < min_support:\n",
    "        combinations_count.pop(combination)\n",
    "\n",
    "print(combinations_count)\n",
    "combined_freq_itemsets.update(combinations_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate generation for 2 or more frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('E', 'G', 'H'): 0}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the combinations if the first k-1 items are the same\n",
    "# and the last item is different\n",
    "# This is done to generate combinations with k+1 items\n",
    "# from combinations with k items\n",
    "\n",
    "# Compare first k-1 items of each combination\n",
    "# If they are the same, merge them\n",
    "# If they are not the same, do not merge them\n",
    "# The merged combinations are stored in a dictionary\n",
    "merged_combinations = {}\n",
    "# for combination1 in combinations_count.keys():\n",
    "#     for combination2 in combinations_count.keys():\n",
    "#         # Check if the first k-1 items are the same\n",
    "#         if combination1[:-1] == combination2[:-1]:\n",
    "#             # Check if the last item is different\n",
    "#             if combination1[-1] != combination2[-1]:\n",
    "#                 # Merge the combinations\n",
    "#                 merged_combinations[combination1 + (combination2[-1],)] = 0\n",
    "\n",
    "for index, combination1 in enumerate(combinations_count.keys()):\n",
    "    for combination2 in list(combinations_count.keys())[index+1:]:\n",
    "        # Check if the first k-1 items are the same\n",
    "        if combination1[:-1] == combination2[:-1]:\n",
    "            # Check if the last item is different\n",
    "            if combination1[-1] != combination2[-1]:\n",
    "                # Merge the combinations\n",
    "                merged_combinations[combination1 + (combination2[-1],)] = 0\n",
    "\n",
    "\n",
    "merged_combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('E', 'G', 'H'): 1}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurences of each combination in the data\n",
    "merged_combinations_count = {}\n",
    "for combination in merged_combinations.keys():\n",
    "    # Using groupby and size to count the number of occurences of each combination\n",
    "    # Resetting the index to get the count of each combination as a column in the dataframe\n",
    "    test = data.groupby(list(combination)).size().reset_index(name='count')\n",
    "\n",
    "    # Append the combination and its count to the dictionary\n",
    "    # The count of each combination is the last value in the count column\n",
    "    # as the last row of the dataframe is when both items are present in one transaction in the original data dataframe\n",
    "    merged_combinations_count[combination] = test['count'].iloc[-1]\n",
    "\n",
    "# print(test)\n",
    "merged_combinations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Prune the combinations with count less than min_support\n",
    "for combination in merged_combinations_count.copy().keys():\n",
    "    if merged_combinations_count[combination] < min_support:\n",
    "        merged_combinations_count.pop(combination)\n",
    "\n",
    "print(merged_combinations_count)\n",
    "combined_freq_itemsets.update(merged_combinations_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A',): 5,\n",
       " ('B',): 5,\n",
       " ('C',): 4,\n",
       " ('D',): 4,\n",
       " ('E',): 8,\n",
       " ('G',): 6,\n",
       " ('H',): 5,\n",
       " ('A', 'E'): 4,\n",
       " ('B', 'E'): 4,\n",
       " ('D', 'E'): 4,\n",
       " ('E', 'G'): 4,\n",
       " ('E', 'H'): 4}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_freq_itemsets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Rule generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('A',), ('E',)): 0.8, (('B',), ('E',)): 0.8, (('D',), ('E',)): 1.0}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate rules for frequent itemsets with k+1 items with min confidence\n",
    "# The rules are generated by splitting the combination into two parts\n",
    "min_confidence = 0.5\n",
    "rules = {}\n",
    "for key in combined_freq_itemsets.keys():\n",
    "    # Split the combination into two parts\n",
    "    # The first part is the antecedent and the second part is the consequent\n",
    "    for i in range(1, len(key)):\n",
    "        antecedent = key[:i]\n",
    "        consequent = key[i:]\n",
    "\n",
    "        # Calculate the confidence of the rule\n",
    "        # Confidence = support of combination / support of antecedent\n",
    "        confidence = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent]\n",
    "\n",
    "        # Check if the confidence is greater than min_confidence\n",
    "        if confidence > min_confidence:\n",
    "            # Append the rule to the rules dictionary\n",
    "            rules[(antecedent, consequent)] = confidence\n",
    "\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('D',), ('E',)): 1.0, (('A',), ('E',)): 0.8, (('B',), ('E',)): 0.8}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prune smaller rules based on confidence of larger rules\n",
    "# If larger rule has confidence less than min_confidence, smaller rules are pruned\n",
    "\n",
    "# Sort the rules in descending order of confidence\n",
    "sorted_rules = sorted(rules.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_rules\n",
    "\n",
    "# Prune the rules\n",
    "pruned_rules = {}\n",
    "for rule in sorted_rules:\n",
    "    # Append the rule to the pruned_rules dictionary if it is not a subset of any rule in the dictionary\n",
    "    if not any([set(rule[0]).issubset(set(pruned_rule[0])) for pruned_rule in pruned_rules.keys()]):\n",
    "        pruned_rules[rule[0]] = rule[1]\n",
    "\n",
    "pruned_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori algorithm\n",
    "# We combine the above steps to generate frequent itemsets with k+1 items\n",
    "# from frequent itemsets with k items\n",
    "# We continue this process until we get no frequent itemsets with k+1 items\n",
    "# We then combine the frequent itemsets with k items to generate association rules\n",
    "# We continue this process until we get no association rules\n",
    "# We then combine the association rules to generate association rules with k+1 items\n",
    "\n",
    "\n",
    "# Function to generate frequent itemsets with 1 item (initialisation)\n",
    "def generate_freq_1_itemsets(data, min_support, combined_freq_itemsets):\n",
    "    # Count the number of 0s and 1s in each column\n",
    "    # The number of 1s is the number of times each item appears\n",
    "    value_counts = data.apply(pd.value_counts)\n",
    "\n",
    "    # Get the frequent itemsets with count greater than or equal to min_support\n",
    "    columns = data.columns\n",
    "    frequent_itemsets = {}\n",
    "    for column in columns:\n",
    "        # Append the itemset and its count to the dictionary if the count is greater than or equal to min_support\n",
    "        if value_counts[column][1] >= min_support:\n",
    "            frequent_itemsets[column] = value_counts[column][1]\n",
    "            # frequent_itemsets.append((column, value_counts[column][1]))\n",
    "            # data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    dummy_dict = frequent_itemsets.copy()\n",
    "    for key, item in dummy_dict.copy().items():\n",
    "        dummy_dict[(tuple(key))] = dummy_dict.pop(key)\n",
    "\n",
    "    combined_freq_itemsets.update(dummy_dict)\n",
    "\n",
    "    print(frequent_itemsets)\n",
    "    return frequent_itemsets\n",
    "\n",
    "\n",
    "# Function to generate frequent itemsets with k+1 items\n",
    "def generate_k_plus_1_candidate_itemsets(frequent_itemsets, k):\n",
    "    # Generate all possible combinations of frequent itemsets with k+1 items\n",
    "\n",
    "    # If k = 1, we do not need to merge the combinations\n",
    "    if k == 1:\n",
    "        combinations = []\n",
    "        combinations.append(list(itertools.combinations(frequent_itemsets.keys(), k+1)))\n",
    "        return combinations\n",
    "    \n",
    "    else:\n",
    "        # Merge the combinations if the first k-1 items are the same\n",
    "        # and the last item is different\n",
    "        # This is done to generate combinations with k+1 items\n",
    "        # from combinations with k items\n",
    "        # Compare first k-1 items of each combination\n",
    "        # If they are the same, merge them\n",
    "        # If they are not the same, do not merge them\n",
    "        # The merged combinations are stored in a dictionary\n",
    "        merged_combinations = {}\n",
    "        \n",
    "\n",
    "        for index, combination1 in enumerate(frequent_itemsets.keys()):\n",
    "            for combination2 in list(frequent_itemsets.keys())[index+1:]:\n",
    "                # Check if the first k-1 items are the same\n",
    "                if combination1[:-1] == combination2[:-1]:\n",
    "                    # Check if the last item is different\n",
    "                    if combination1[-1] != combination2[-1]:\n",
    "                        # Merge the combinations\n",
    "                        merged_combinations[combination1 + (combination2[-1],)] = 0\n",
    "\n",
    "    \n",
    "        return merged_combinations\n",
    "\n",
    "# Function to count the number of occurences of each combination in the candidate itemsets\n",
    "def k_plus_1_itemsets_support_counting(k_plus_1_candidate_itemsets, k):\n",
    "    # If k = 1, we need to convert the list of lists of tuples to a list of tuples\n",
    "    if k == 1:\n",
    "        k_plus_1_candidate_itemsets = k_plus_1_candidate_itemsets[0]\n",
    "\n",
    "    # Count the number of occurences of each combination in the data\n",
    "    candidate_itemsets_count = {}\n",
    "    for candidate_itemset in k_plus_1_candidate_itemsets:\n",
    "        # Using groupby and size to count the number of occurences of each combination\n",
    "        # Resetting the index to get the count of each combination as a column in the dataframe\n",
    "        test = data.groupby(list(candidate_itemset)).size().reset_index(name='count')\n",
    "\n",
    "        # Append the combination and its count to the dictionary\n",
    "        # The count of each combination is the last value in the count column\n",
    "        # as the last row of the dataframe is when both items are present in one transaction in the original data dataframe\n",
    "        candidate_itemsets_count[candidate_itemset] = test['count'].iloc[-1]\n",
    "\n",
    "    return candidate_itemsets_count\n",
    "\n",
    "\n",
    "def candidate_elimination(combinations_count, min_support, combined_freq_itemsets):\n",
    "    \n",
    "    # Prune the combinations with count less than min_support\n",
    "    for combination in combinations_count.copy().keys():\n",
    "        if combinations_count[combination] < min_support:\n",
    "            combinations_count.pop(combination)\n",
    "    \n",
    "    combined_freq_itemsets.update(combinations_count)\n",
    "    return combinations_count\n",
    "\n",
    "def generate_rules(combined_freq_itemsets, min_confidence):\n",
    "    # Generate rules for frequent itemsets with k+1 items with min confidence\n",
    "    # The rules are generated by splitting the combination into two parts\n",
    "    rules = {}\n",
    "    for key in combined_freq_itemsets.keys():\n",
    "        # Split the combination into two parts\n",
    "        # The first part is the antecedent and the second part is the consequent\n",
    "        for i in range(1, len(key)):\n",
    "            antecedent = key[:i]\n",
    "            consequent = key[i:]\n",
    "\n",
    "            # Calculate the confidence of the rule\n",
    "            # Confidence = support of combination / support of antecedent\n",
    "            confidence = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent]\n",
    "\n",
    "            # Check if the confidence is greater than min_confidence\n",
    "            if confidence > min_confidence:\n",
    "                # Append the rule to the rules dictionary\n",
    "                rules[(antecedent, consequent)] = confidence\n",
    "\n",
    "    return rules\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 5, 'B': 5, 'C': 4, 'D': 4, 'E': 8, 'G': 6, 'H': 5}\n",
      "Combined frequent itemsets {('A',): 5, ('B',): 5, ('C',): 4, ('D',): 4, ('E',): 8, ('G',): 6, ('H',): 5, ('A', 'E'): 4, ('B', 'E'): 4, ('D', 'E'): 4, ('E', 'G'): 4, ('E', 'H'): 4}\n"
     ]
    }
   ],
   "source": [
    "def apriori(data, min_support, min_confidence):\n",
    "    \n",
    "    # Combined dictionary of frequent itemsets\n",
    "    combined_freq_itemsets = {}\n",
    "\n",
    "    # Get frequent 1 itemsets\n",
    "    frequent_1_itemsets = generate_freq_1_itemsets(data, min_support, combined_freq_itemsets)\n",
    "\n",
    "    k_plus_1_candidate_itemsets = None\n",
    "    k_plus_1_itemsets_support_count = None\n",
    "    k_plus_1_frequent_itemsets = None\n",
    "    \n",
    "    k = 1\n",
    "\n",
    "    while True:\n",
    "        # print(k)\n",
    "        if k == 1:\n",
    "            k_plus_1_candidate_itemsets = generate_k_plus_1_candidate_itemsets(frequent_1_itemsets, k)\n",
    "        else:\n",
    "            k_plus_1_candidate_itemsets = generate_k_plus_1_candidate_itemsets(k_plus_1_frequent_itemsets, k)\n",
    "        \n",
    "        # print(k_plus_1_candidate_itemsets)\n",
    "        k_plus_1_itemsets_support_count = k_plus_1_itemsets_support_counting(k_plus_1_candidate_itemsets, k)\n",
    "        \n",
    "        k_plus_1_frequent_itemsets = candidate_elimination(k_plus_1_itemsets_support_count, min_support, combined_freq_itemsets)\n",
    "        # print(k_plus_1_frequent_itemsets)\n",
    "        k += 1\n",
    "        \n",
    "        # If there are no frequent itemsets with k+1 items, break\n",
    "        if len(k_plus_1_frequent_itemsets) == 0:\n",
    "            break\n",
    "\n",
    "    # Generate rules for frequent itemsets with k+1 items with min confidence\n",
    "    # The rules are generated by splitting the combination into two parts\n",
    "    rules = generate_rules(combined_freq_itemsets, min_confidence)\n",
    "    \n",
    "    return combined_freq_itemsets, rules\n",
    "\n",
    "\n",
    "combined_freq_itemsets, rules = apriori(data, 4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined frequent itemsets:  {('A',): 5, ('B',): 5, ('C',): 4, ('D',): 4, ('E',): 8, ('G',): 6, ('H',): 5, ('A', 'E'): 4, ('B', 'E'): 4, ('D', 'E'): 4, ('E', 'G'): 4, ('E', 'H'): 4}\n"
     ]
    }
   ],
   "source": [
    "print('combined frequent itemsets: ', combined_freq_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antecedent:  ['A'] consequent:  ['E'] confidence:  0.8\n",
      "antecedent:  ['B'] consequent:  ['E'] confidence:  0.8\n",
      "antecedent:  ['D'] consequent:  ['E'] confidence:  1.0\n"
     ]
    }
   ],
   "source": [
    "for key, item in rules.items():\n",
    "    for i in range(1, len(key)):\n",
    "        antecedent = key[:i]\n",
    "        consequent = key[i:]\n",
    "        print('antecedent: ', list(sum(antecedent, ())), 'consequent: ', list(sum(consequent, ())), 'confidence: ', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
