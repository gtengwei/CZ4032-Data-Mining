{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Task 1: Implement the Apriori algorithm to mine frequent itemsets </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  F  G  H\n",
       "0  0  1  1  1  1  0  0  0\n",
       "1  0  1  0  0  1  1  1  1\n",
       "2  0  0  1  0  1  0  0  0\n",
       "3  1  0  1  1  0  1  0  1\n",
       "4  0  0  1  1  1  0  1  0\n",
       "5  0  0  1  1  0  1  0  0\n",
       "6  1  0  1  0  0  0  0  0\n",
       "7  1  1  1  1  0  0  0  1\n",
       "8  0  1  0  0  1  1  1  1\n",
       "9  1  0  1  1  0  1  0  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dummy data\n",
    "data = pd.DataFrame(np.random.randint(0, 2, size=(10, 8)), columns=list('ABCDEFGH'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D  E  F  G  H\n",
       "0  6  6  2  4  5  5  7  6\n",
       "1  4  4  8  6  5  5  3  4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of 0s and 1s in each column\n",
    "# The number of 1s is the number of times each item appears\n",
    "value_counts = data.apply(pd.value_counts)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts['A'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lecture notes explanation of the Apriori Algorithm, we have 4 steps to do.\n",
    "1. Candidate Generation\n",
    "2. Candidate Pruning\n",
    "3. Support Counting\n",
    "4. Candidate Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for 1 and 2 itemset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the min support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined dictionary of frequent itemsets\n",
    "combined_freq_itemsets = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate F1 (frequent 1-itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 4, 'B': 4, 'C': 8, 'D': 6, 'E': 5, 'F': 5, 'H': 4}\n",
      "{('A',): 4, ('B',): 4, ('C',): 8, ('D',): 6, ('E',): 5, ('F',): 5, ('H',): 4}\n"
     ]
    }
   ],
   "source": [
    "# Get the frequent itemsets with count greater than or equal to min_support\n",
    "columns = data.columns\n",
    "frequent_itemsets = {}\n",
    "for column in columns:\n",
    "    # Append the itemset and its count to the dictionary if the count is greater than or equal to min_support\n",
    "    if value_counts[column][1] >= min_support:\n",
    "        frequent_itemsets[column] = value_counts[column][1]\n",
    "        # frequent_itemsets.append((column, value_counts[column][1]))\n",
    "        # data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "print(frequent_itemsets)\n",
    "\n",
    "dummy_dict = frequent_itemsets.copy()\n",
    "for key, item in dummy_dict.copy().items():\n",
    "    dummy_dict[(tuple(key))] = dummy_dict.pop(key)\n",
    "print(dummy_dict)\n",
    "    \n",
    "combined_freq_itemsets.update(dummy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('A', 'B'),\n",
       "  ('A', 'C'),\n",
       "  ('A', 'D'),\n",
       "  ('A', 'E'),\n",
       "  ('A', 'F'),\n",
       "  ('A', 'H'),\n",
       "  ('B', 'C'),\n",
       "  ('B', 'D'),\n",
       "  ('B', 'E'),\n",
       "  ('B', 'F'),\n",
       "  ('B', 'H'),\n",
       "  ('C', 'D'),\n",
       "  ('C', 'E'),\n",
       "  ('C', 'F'),\n",
       "  ('C', 'H'),\n",
       "  ('D', 'E'),\n",
       "  ('D', 'F'),\n",
       "  ('D', 'H'),\n",
       "  ('E', 'F'),\n",
       "  ('E', 'H'),\n",
       "  ('F', 'H')]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate all possible combinations of frequent itemsets with k+1 items\n",
    "combinations = []\n",
    "k = 1\n",
    "combinations.append(list(itertools.combinations(frequent_itemsets.keys(), k+1)))\n",
    "\n",
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Candidate Pruning (do not need to prune for 2 itemset as F1 items are all frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Support Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of lists of tuples to a list of tuples\n",
    "combinations = combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'B'): 1,\n",
       " ('A', 'C'): 4,\n",
       " ('A', 'D'): 3,\n",
       " ('A', 'F'): 2,\n",
       " ('A', 'H'): 2,\n",
       " ('B', 'C'): 2,\n",
       " ('B', 'D'): 2,\n",
       " ('B', 'E'): 3,\n",
       " ('B', 'F'): 2,\n",
       " ('B', 'H'): 3,\n",
       " ('C', 'D'): 6,\n",
       " ('C', 'E'): 3,\n",
       " ('C', 'F'): 3,\n",
       " ('C', 'H'): 2,\n",
       " ('D', 'E'): 2,\n",
       " ('D', 'F'): 3,\n",
       " ('D', 'H'): 2,\n",
       " ('E', 'F'): 2,\n",
       " ('E', 'H'): 2,\n",
       " ('F', 'H'): 3}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurences of each combination in the data\n",
    "combinations_count = {}\n",
    "for combination in combinations:\n",
    "    # Using groupby and size to count the number of occurences of each combination\n",
    "    # Resetting the index to get the count of each combination as a column in the dataframe\n",
    "    test = data.groupby(list(combination)).size().reset_index(name='count')\n",
    "    \n",
    "    # Append the combination and its count to the dictionary\n",
    "    # The count of each combination is the last value in the count column\n",
    "    # Moreover, we need to check whether the last row is a combination of 1s instead of 1s and 0s\n",
    "    # If it is a combination of 1s, then we append the combination and its count to the dictionary\n",
    "    # Otherwise, we do not append it to the dictionary\n",
    "    if test[test.columns[0]].iloc[-1] == 1 and test[test.columns[1]].iloc[-1] == 1:\n",
    "        combinations_count[combination] = test['count'].iloc[-1]\n",
    "\n",
    "# print(test)\n",
    "combinations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.index.values[-1].count(1)\n",
    "test1 = test\n",
    "count = test1['count'].iloc[-1]\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Candidate Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('A', 'C'): 4, ('C', 'D'): 6}\n"
     ]
    }
   ],
   "source": [
    "# Prune the combinations with count less than min_support\n",
    "for combination in combinations_count.copy().keys():\n",
    "    if combinations_count[combination] < min_support:\n",
    "        combinations_count.pop(combination)\n",
    "\n",
    "print(combinations_count)\n",
    "combined_freq_itemsets.update(combinations_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate generation for 2 or more frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the combinations if the first k-1 items are the same\n",
    "# and the last item is different\n",
    "# This is done to generate combinations with k+1 items\n",
    "# from combinations with k items\n",
    "\n",
    "# Compare first k-1 items of each combination\n",
    "# If they are the same, merge them\n",
    "# If they are not the same, do not merge them\n",
    "# The merged combinations are stored in a dictionary\n",
    "merged_combinations = {}\n",
    "# for combination1 in combinations_count.keys():\n",
    "#     for combination2 in combinations_count.keys():\n",
    "#         # Check if the first k-1 items are the same\n",
    "#         if combination1[:-1] == combination2[:-1]:\n",
    "#             # Check if the last item is different\n",
    "#             if combination1[-1] != combination2[-1]:\n",
    "#                 # Merge the combinations\n",
    "#                 merged_combinations[combination1 + (combination2[-1],)] = 0\n",
    "\n",
    "for index, combination1 in enumerate(combinations_count.keys()):\n",
    "    for combination2 in list(combinations_count.keys())[index+1:]:\n",
    "        # Check if the first k-1 items are the same\n",
    "        if combination1[:-1] == combination2[:-1]:\n",
    "            # Check if the last item is different\n",
    "            if combination1[-1] != combination2[-1]:\n",
    "                # Merge the combinations\n",
    "                merged_combinations[combination1 + (combination2[-1],)] = 0\n",
    "\n",
    "\n",
    "merged_combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurences of each combination in the data\n",
    "merged_combinations_count = {}\n",
    "for combination in merged_combinations.keys():\n",
    "    # Using groupby and size to count the number of occurences of each combination\n",
    "    # Resetting the index to get the count of each combination as a column in the dataframe\n",
    "    test = data.groupby(list(combination)).size().reset_index(name='count')\n",
    "\n",
    "    # Append the combination and its count to the dictionary\n",
    "    # The count of each combination is the last value in the count column\n",
    "    # as the last row of the dataframe is when both items are present in one transaction in the original data dataframe\n",
    "    merged_combinations_count[combination] = test['count'].iloc[-1]\n",
    "\n",
    "# print(test)\n",
    "merged_combinations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Prune the combinations with count less than min_support\n",
    "for combination in merged_combinations_count.copy().keys():\n",
    "    if merged_combinations_count[combination] < min_support:\n",
    "        merged_combinations_count.pop(combination)\n",
    "\n",
    "print(merged_combinations_count)\n",
    "combined_freq_itemsets.update(merged_combinations_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A',): 4,\n",
       " ('B',): 4,\n",
       " ('C',): 8,\n",
       " ('D',): 6,\n",
       " ('E',): 5,\n",
       " ('F',): 5,\n",
       " ('H',): 4,\n",
       " ('A', 'C'): 4,\n",
       " ('C', 'D'): 6}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_freq_itemsets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Rule generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mineral Water',), ('Ground Beef',), ('Spagetti',)]\n",
      "('Mineral Water',)\n",
      "('Ground Beef',)\n",
      "('Spagetti',)\n",
      "[('Mineral Water', 'Ground Beef'), ('Mineral Water', 'Spagetti'), ('Ground Beef', 'Spagetti')]\n",
      "('Mineral Water', 'Ground Beef')\n",
      "('Mineral Water', 'Spagetti')\n",
      "('Ground Beef', 'Spagetti')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Mineral Water', 'Ground Beef'),\n",
       " ('Mineral Water', 'Spagetti'),\n",
       " ('Ground Beef', 'Spagetti')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = ['Mineral Water', 'Ground Beef', 'Spagetti']\n",
    "\n",
    "for i in range(1, len(lis)):  #  xrange will return the values 1,2,3,4 in this loop\n",
    "    combinations = []\n",
    "    combinations.append(list(itertools.combinations(lis, i)))\n",
    "    if combinations:\n",
    "        combinations = combinations[0]\n",
    "        print(combinations)\n",
    "        for combination in combinations:\n",
    "            print(combination)\n",
    "\n",
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('A',), ('C',)): 1.0,\n",
       " (('C',), ('A',)): 0.5,\n",
       " (('C',), ('D',)): 0.75,\n",
       " (('D',), ('C',)): 1.0}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate rules for frequent itemsets with k+1 items with min confidence\n",
    "# The rules are generated by splitting the combination into two parts\n",
    "min_confidence = 0.5\n",
    "rules = {}\n",
    "for key in combined_freq_itemsets.keys():\n",
    "    combinations = []\n",
    "    for i in range(1, len(key)):  #  xrange will return the values 1,2,3,4 in this loop\n",
    "        combinations.append(list(itertools.combinations(key, i)))\n",
    "        if combinations:\n",
    "            combinations = combinations[0]\n",
    "            for combination in combinations:\n",
    "                antecedent = combination\n",
    "                consequent = tuple(set(key) - set(combination))\n",
    "                confidence = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent]\n",
    "                if confidence >= min_confidence:\n",
    "                    rules[(antecedent, consequent)] = confidence\n",
    "    # Split the combination into two parts\n",
    "    # The first part is the antecedent and the second part is the consequent\n",
    "    # for i in range(1, len(key)):\n",
    "    #     antecedent_1 = key[:i]\n",
    "    #     consequent_1 = key[i:]\n",
    "\n",
    "    #     antecedent_2 = key[i:]\n",
    "    #     consequent_2 = key[:i]\n",
    "\n",
    "    #     # Calculate the confidence of the rule\n",
    "    #     # Confidence = support of combination / support of antecedent\n",
    "    #     confidence_1 = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent_1]\n",
    "    #     confidence_2 = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent_2]\n",
    "\n",
    "    #     # Check if the confidence is greater than min_confidence\n",
    "    #     if confidence_1 >= min_confidence:\n",
    "    #         # Append the rule to the rules dictionary\n",
    "    #         rules[(antecedent_1, consequent_1)] = confidence_1\n",
    "        \n",
    "    #     if confidence_2 >= min_confidence:\n",
    "    #         # Append the rule to the rules dictionary\n",
    "    #         rules[(antecedent_2, consequent_2)] = confidence_2\n",
    "\n",
    "rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('A',), ('C',)): 1.0,\n",
       " (('A',), ('E',)): 1.0,\n",
       " (('A',), ('C', 'E')): 1.0,\n",
       " (('A', 'C'), ('E',)): 1.0,\n",
       " (('C',), ('D',)): 0.75}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prune smaller rules based on confidence of larger rules\n",
    "# If larger rule has confidence less than min_confidence, smaller rules are pruned\n",
    "\n",
    "# Sort the rules in descending order of confidence\n",
    "sorted_rules = sorted(rules.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_rules\n",
    "\n",
    "# Prune the rules\n",
    "pruned_rules = {}\n",
    "for rule in sorted_rules:\n",
    "    # Append the rule to the pruned_rules dictionary if it is not a subset of any rule in the dictionary\n",
    "    if not any([set(rule[0]).issubset(set(pruned_rule[0])) for pruned_rule in pruned_rules.keys()]):\n",
    "        pruned_rules[rule[0]] = rule[1]\n",
    "\n",
    "pruned_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori algorithm\n",
    "# We combine the above steps to generate frequent itemsets with k+1 items\n",
    "# from frequent itemsets with k items\n",
    "# We continue this process until we get no frequent itemsets with k+1 items\n",
    "# We then combine the frequent itemsets with k items to generate association rules\n",
    "# We continue this process until we get no association rules\n",
    "# We then combine the association rules to generate association rules with k+1 items\n",
    "\n",
    "\n",
    "# Function to generate frequent itemsets with 1 item (initialisation)\n",
    "def generate_freq_1_itemsets(data, min_support, combined_freq_itemsets):\n",
    "\n",
    "    # Count the number of 0s and 1s in each column\n",
    "    # The number of 1s is the number of times each item appears\n",
    "    value_counts = data.apply(pd.value_counts)\n",
    "\n",
    "    # Get the frequent itemsets with count greater than or equal to min_support\n",
    "    columns = data.columns\n",
    "    frequent_itemsets = {}\n",
    "    for column in columns:\n",
    "        # Append the itemset and its count to the dictionary if the count is greater than or equal to min_support\n",
    "        if value_counts[column][1] >= min_support:\n",
    "            frequent_itemsets[column] = value_counts[column][1]\n",
    "            # frequent_itemsets.append((column, value_counts[column][1]))\n",
    "            # data.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    dummy_dict = frequent_itemsets.copy()\n",
    "    for key, item in dummy_dict.copy().items():\n",
    "        # For dummy data\n",
    "        # dummy_dict[(tuple(key))] = dummy_dict.pop(key)\n",
    "        # For real data\n",
    "        dummy_dict[(key,)] = dummy_dict.pop(key)\n",
    "    print(dummy_dict)\n",
    "\n",
    "    combined_freq_itemsets.update(dummy_dict)\n",
    "\n",
    "    print(frequent_itemsets)\n",
    "    return frequent_itemsets\n",
    "\n",
    "\n",
    "# Function to generate frequent itemsets with k+1 items\n",
    "def generate_k_plus_1_candidate_itemsets(frequent_itemsets, k):\n",
    "    # Generate all possible combinations of frequent itemsets with k+1 items\n",
    "\n",
    "    # If k = 1, we do not need to merge the combinations\n",
    "    if k == 1:\n",
    "        combinations = []\n",
    "        combinations.append(list(itertools.combinations(frequent_itemsets.keys(), k+1)))\n",
    "        return combinations\n",
    "    \n",
    "    else:\n",
    "        # Merge the combinations if the first k-1 items are the same\n",
    "        # and the last item is different\n",
    "        # This is done to generate combinations with k+1 items\n",
    "        # from combinations with k items\n",
    "        # Compare first k-1 items of each combination\n",
    "        # If they are the same, merge them\n",
    "        # If they are not the same, do not merge them\n",
    "        # The merged combinations are stored in a dictionary\n",
    "        merged_combinations = {}\n",
    "        \n",
    "\n",
    "        for index, combination1 in enumerate(frequent_itemsets.keys()):\n",
    "            for combination2 in list(frequent_itemsets.keys())[index+1:]:\n",
    "                # Check if the first k-1 items are the same\n",
    "                if combination1[:-1] == combination2[:-1]:\n",
    "                    # Check if the last item is different\n",
    "                    if combination1[-1] != combination2[-1]:\n",
    "                        # Merge the combinations\n",
    "                        merged_combinations[combination1 + (combination2[-1],)] = 0\n",
    "\n",
    "    \n",
    "        return merged_combinations\n",
    "\n",
    "# Function to count the number of occurences of each combination in the candidate itemsets\n",
    "def k_plus_1_itemsets_support_counting(k_plus_1_candidate_itemsets, k, data):\n",
    "    # If k = 1, we need to convert the list of lists of tuples to a list of tuples\n",
    "    if k == 1:\n",
    "        k_plus_1_candidate_itemsets = k_plus_1_candidate_itemsets[0]\n",
    "\n",
    "    # Count the number of occurences of each combination in the data\n",
    "    candidate_itemsets_count = {}\n",
    "    for candidate_itemset in k_plus_1_candidate_itemsets:\n",
    "        # Using groupby and size to count the number of occurences of each combination\n",
    "        # Resetting the index to get the count of each combination as a column in the dataframe\n",
    "        test = data.groupby(list(candidate_itemset)).size().reset_index(name='count')\n",
    "\n",
    "        # Append the combination and its count to the dictionary\n",
    "        # The count of each combination is the last value in the count column\n",
    "        # Moreover, we need to check whether the last row is a combination of 1s instead of 1s and 0s\n",
    "        # If it is a combination of 1s, then we append the combination and its count to the dictionary\n",
    "        # Otherwise, we do not append it to the dictionary\n",
    "        # if test[test.columns[0]].iloc[-1] == 1 and test[test.columns[1]].iloc[-1] == 1:\n",
    "        #     candidate_itemsets_count[candidate_itemset] = test['count'].iloc[-1]\n",
    "        num_ones = 0\n",
    "        for i in range(len(test.columns)-1):\n",
    "            if test[test.columns[i]].iloc[-1] != 1:\n",
    "                break\n",
    "            else:\n",
    "                num_ones += 1\n",
    "                continue\n",
    "            \n",
    "        if num_ones == len(test.columns)-1:\n",
    "            candidate_itemsets_count[candidate_itemset] = test['count'].iloc[-1]\n",
    "\n",
    "    return candidate_itemsets_count\n",
    "\n",
    "\n",
    "def candidate_elimination(combinations_count, min_support, combined_freq_itemsets):\n",
    "    \n",
    "    # Prune the combinations with count less than min_support\n",
    "    for combination in combinations_count.copy().keys():\n",
    "        if combinations_count[combination] < min_support:\n",
    "            combinations_count.pop(combination)\n",
    "    \n",
    "    combined_freq_itemsets.update(combinations_count)\n",
    "    return combinations_count\n",
    "\n",
    "def generate_rules(combined_freq_itemsets, min_confidence, target):\n",
    "    # Generate rules for frequent itemsets with k+1 items with min confidence\n",
    "    # The rules are generated by splitting the combination into two parts\n",
    "    rules = {}\n",
    "    for key in combined_freq_itemsets.keys():\n",
    "        \n",
    "        for i in range(1, len(key)):  # range will return the values 1,2,3,4 in this loop\n",
    "            combinations = []\n",
    "            combinations.append(list(itertools.combinations(key, i)))\n",
    "            # print(target, key, combinations)\n",
    "            if combinations:\n",
    "                combinations = combinations[0]\n",
    "                for combination in combinations:\n",
    "                    \n",
    "                    # Convert the combination to a tuple if it is a string\n",
    "                    if type(combination) == str:\n",
    "                        combination = (combination,)\n",
    "                    \n",
    "                    # Check if the target is in the combination\n",
    "                    if target != None:\n",
    "                        # Continue to the next combination if the target is not in the combination\n",
    "                        if target not in combination or len(combination) == 1:\n",
    "                            continue\n",
    "                        \n",
    "                        # Split the combination into two parts\n",
    "                        # The first part is the antecedent and the second part is the consequent\n",
    "                        # The antecedent is the combination without the target\n",
    "                        # The consequent is the target\n",
    "\n",
    "                        temp_target = (target,)\n",
    "                        \n",
    "                        # In order to keep the correct order of the items in the combination\n",
    "                        difference = set(combination) - set(temp_target)\n",
    "                        antecedent = tuple(item for item in combination if item in difference)\n",
    "                        consequent = temp_target\n",
    "\n",
    "                    # If the target is None, then we do not need to assign the target to the consequent\n",
    "                    else:\n",
    "                        antecedent = combination\n",
    "                        difference = set(key) - set(combination)\n",
    "                        consequent = tuple(item for item in key if item in difference)\n",
    "                    # print(target, combination)\n",
    "                    # print(\"Combinations is \", combinations, \"Combination is: \", combination, \"Antecedent is: \", antecedent, \"Consequent is: \", consequent)\n",
    "                    confidence = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent]\n",
    "                    # print('antecedent: ', antecedent, 'consequent: ', consequent, 'confidence: ', confidence)\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules[(antecedent, consequent)] = confidence\n",
    "                        \n",
    "        # Split the combination into two parts\n",
    "        # The first part is the antecedent and the second part is the consequent\n",
    "        # for i in range(1, len(key)):\n",
    "        #     antecedent_1 = key[:i]\n",
    "        #     consequent_1 = key[i:]\n",
    "\n",
    "        #     antecedent_2 = key[i:]\n",
    "        #     consequent_2 = key[:i]\n",
    "        #     # Calculate the confidence of the rule\n",
    "        #     # Confidence = support of combination / support of antecedent\n",
    "        #     confidence_1 = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent_1]\n",
    "        #     confidence_2 = combined_freq_itemsets[key] / combined_freq_itemsets[antecedent_2]\n",
    "\n",
    "        #     print(antecedent_1, consequent_1, confidence_1)\n",
    "        #     print(antecedent_2, consequent_2, confidence_2)\n",
    "        #     # Check if the confidence is greater than min_confidence\n",
    "        #     if confidence_1 >= min_confidence:\n",
    "        #         # Append the rule to the rules dictionary\n",
    "        #         rules[(antecedent_1, consequent_1)] = confidence_1\n",
    "\n",
    "        #     if confidence_2 >= min_confidence:\n",
    "        #         # Append the rule to the rules dictionary\n",
    "        #         rules[(antecedent_2, consequent_2)] = confidence_2\n",
    "                \n",
    "    return rules\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_apriori(data, min_support, min_confidence, target=None):\n",
    "    \n",
    "    # Combined dictionary of frequent itemsets\n",
    "    combined_freq_itemsets = {}\n",
    "\n",
    "    # Get frequent 1 itemsets\n",
    "    frequent_1_itemsets = generate_freq_1_itemsets(data, min_support, combined_freq_itemsets)\n",
    "\n",
    "    k_plus_1_candidate_itemsets = None\n",
    "    k_plus_1_itemsets_support_count = None\n",
    "    k_plus_1_frequent_itemsets = None\n",
    "    \n",
    "    k = 1\n",
    "\n",
    "    while True:\n",
    "        # print(k)\n",
    "        if k == 1:\n",
    "            k_plus_1_candidate_itemsets = generate_k_plus_1_candidate_itemsets(frequent_1_itemsets, k)\n",
    "        else:\n",
    "            k_plus_1_candidate_itemsets = generate_k_plus_1_candidate_itemsets(k_plus_1_frequent_itemsets, k)\n",
    "        print(combined_freq_itemsets)\n",
    "        # print(k_plus_1_candidate_itemsets)\n",
    "        k_plus_1_itemsets_support_count = k_plus_1_itemsets_support_counting(k_plus_1_candidate_itemsets, k, data)\n",
    "        \n",
    "        k_plus_1_frequent_itemsets = candidate_elimination(k_plus_1_itemsets_support_count, min_support, combined_freq_itemsets)\n",
    "        # print(k_plus_1_frequent_itemsets)\n",
    "        k += 1\n",
    "        print('k: ', k)\n",
    "        # If there are no frequent itemsets with k+1 items, break\n",
    "        if len(k_plus_1_frequent_itemsets) == 0:\n",
    "            break\n",
    "\n",
    "    # Generate rules for frequent itemsets with k+1 items with min confidence\n",
    "    # The rules are generated by splitting the combination into two parts\n",
    "    rules = generate_rules(combined_freq_itemsets, min_confidence, target)\n",
    "    \n",
    "    return combined_freq_itemsets, rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('A',): 4, ('B',): 4, ('C',): 8, ('D',): 6, ('E',): 5, ('F',): 5, ('H',): 4}\n",
      "{'A': 4, 'B': 4, 'C': 8, 'D': 6, 'E': 5, 'F': 5, 'H': 4}\n",
      "{('A',): 4, ('B',): 4, ('C',): 8, ('D',): 6, ('E',): 5, ('F',): 5, ('H',): 4}\n",
      "k:  2\n",
      "{('A',): 4, ('B',): 4, ('C',): 8, ('D',): 6, ('E',): 5, ('F',): 5, ('H',): 4, ('A', 'C'): 4, ('C', 'D'): 6}\n",
      "k:  3\n"
     ]
    }
   ],
   "source": [
    "combined_freq_itemsets, rules = my_apriori(data, 4, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined frequent itemsets:  {('A',): 4, ('B',): 4, ('C',): 8, ('D',): 6, ('E',): 5, ('F',): 5, ('H',): 4, ('A', 'C'): 4, ('C', 'D'): 6}\n"
     ]
    }
   ],
   "source": [
    "print('combined frequent itemsets: ', combined_freq_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(A,)</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(B,)</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(C,)</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(D,)</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(E,)</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(F,)</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(H,)</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(A, C)</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(C, D)</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        support\n",
       "(A,)          4\n",
       "(B,)          4\n",
       "(C,)          8\n",
       "(D,)          6\n",
       "(E,)          5\n",
       "(F,)          5\n",
       "(H,)          4\n",
       "(A, C)        4\n",
       "(C, D)        6"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_itemsets_df = pd.DataFrame.from_dict(combined_freq_itemsets, orient='index', columns=['support'])\n",
    "freq_itemsets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rules:  {(('A',), ('C',)): 1.0, (('C',), ('A',)): 0.5, (('C',), ('D',)): 0.75, (('D',), ('C',)): 1.0}\n",
      "antecedent:  ['A'] -> consequent:  ['C'] confidence:  1.0\n",
      "antecedent:  ['C'] -> consequent:  ['A'] confidence:  0.5\n",
      "antecedent:  ['C'] -> consequent:  ['D'] confidence:  0.75\n",
      "antecedent:  ['D'] -> consequent:  ['C'] confidence:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('rules: ', rules)\n",
    "for key, item in rules.items():\n",
    "    for i in range(1, len(key)):\n",
    "        antecedent = key[:i]\n",
    "        consequent = key[i:]\n",
    "        print('antecedent: ', list(sum(antecedent, ())), '-> consequent: ', list(sum(consequent, ())), 'confidence: ', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Showing the results of my code is correct by using the actual official Apriori algorithm library extension </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Obtaining dependency information for mlxtend from https://files.pythonhosted.org/packages/73/da/d5d77a9a7a135c948dbf8d3b873655b105a152d69e590150c83d23c3d070/mlxtend-0.23.0-py3-none-any.whl.metadata\n",
      "  Downloading mlxtend-0.23.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (3.6.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.37.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tengwei\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.4 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3\n",
      "[notice] To update, run: C:\\Users\\tengwei\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tengwei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(F)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(H)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4</td>\n",
       "      <td>(C, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(C, D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support itemsets\n",
       "0      0.4      (A)\n",
       "1      0.4      (B)\n",
       "2      0.8      (C)\n",
       "3      0.6      (D)\n",
       "4      0.5      (E)\n",
       "5      0.5      (F)\n",
       "6      0.4      (H)\n",
       "7      0.4   (C, A)\n",
       "8      0.6   (C, D)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "freq_items = apriori(data, min_support=0.4, use_colnames=True)\n",
    "freq_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(A)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(A)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(C)</td>\n",
       "      <td>(D)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(D)</td>\n",
       "      <td>(C)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  antecedents consequents  antecedent support  consequent support  support  \\\n",
       "0         (C)         (A)                 0.8                 0.4      0.4   \n",
       "1         (A)         (C)                 0.4                 0.8      0.4   \n",
       "2         (C)         (D)                 0.8                 0.6      0.6   \n",
       "3         (D)         (C)                 0.6                 0.8      0.6   \n",
       "\n",
       "   confidence  lift  leverage  conviction  zhangs_metric  \n",
       "0        0.50  1.25      0.08         1.2       1.000000  \n",
       "1        1.00  1.25      0.08         inf       0.333333  \n",
       "2        0.75  1.25      0.12         1.6       1.000000  \n",
       "3        1.00  1.25      0.12         inf       0.500000  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = association_rules(freq_items, metric='confidence', min_threshold=0.5)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Task 2: Use 3 datasets to run Apriori algorithm with different min-support thresholds </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Grocery store dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Market_Basket_Optimisation.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs                 0             0   \n",
       "2        chutney          0           0                 0             0   \n",
       "3         turkey    avocado           0                 0             0   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1                 0     0               0             0             0   \n",
       "2                 0     0               0             0             0   \n",
       "3                 0     0               0             0             0   \n",
       "4                 0     0               0             0             0   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1               0          0      0      0              0       0   \n",
       "2               0          0      0      0              0       0   \n",
       "3               0          0      0      0              0       0   \n",
       "4               0          0      0      0              0       0   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                  0                0        0          0  \n",
       "2                  0                0        0          0  \n",
       "3                  0                0        0          0  \n",
       "4                  0                0        0          0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data CLeaning\n",
    "df.fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shrimp', 'burgers', 'chutney', 'turkey', 'mineral water',\n",
       "       'low fat yogurt', 'whole wheat pasta', 'soup', 'frozen vegetables',\n",
       "       'french fries', 'eggs', 'cookies', 'spaghetti', 'meatballs',\n",
       "       'red wine', 'rice', 'parmesan cheese', 'ground beef',\n",
       "       'sparkling water', 'herb & pepper', 'pickles', 'energy bar',\n",
       "       'fresh tuna', 'escalope', 'avocado', 'tomato sauce',\n",
       "       'clothes accessories', 'energy drink', 'chocolate',\n",
       "       'grated cheese', 'yogurt cake', 'mint', 'asparagus', 'champagne',\n",
       "       'ham', 'muffins', 'french wine', 'chicken', 'pasta', 'tomatoes',\n",
       "       'pancakes', 'frozen smoothie', 'carrots', 'yams', 'shallot',\n",
       "       'butter', 'light mayo', 'pepper', 'candy bars', 'cooking oil',\n",
       "       'milk', 'green tea', 'bug spray', 'oil', 'olive oil', 'salmon',\n",
       "       'cake', 'almonds', 'salt', 'strong cheese', 'hot dogs', 'pet food',\n",
       "       'whole wheat rice', 'antioxydant juice', 'honey', 'sandwich',\n",
       "       'salad', 'magazines', 'protein bar', 'mayonnaise', 'cider',\n",
       "       'burger sauce', 'green grapes', 'vegetables mix', 'bramble',\n",
       "       'nonfat milk', 'tomato juice', 'green beans', 'strawberries',\n",
       "       'eggplant', 'mushroom cream sauce', 'gums', 'cereals', 'flax seed',\n",
       "       'spinach', 'soda', 'dessert wine', 'corn', 'fresh bread',\n",
       "       'brownies', 'fromage blanc', 'chocolate bread', 'mashed potato',\n",
       "       'gluten free bar', 'cottage cheese', 'whole weat flour', 'chili',\n",
       "       'barbecue sauce', 'light cream', 'mint green tea', 'black tea',\n",
       "       'bacon', 'shampoo', 'blueberries', 'cauliflower',\n",
       "       'extra dark chocolate', 'white wine', 'babies food', 'toothpaste',\n",
       "       'melons', 'ketchup', 'cream', 'hand protein bar', 'body spray',\n",
       "       'oatmeal', 0, 'zucchini', 'water spray', 'tea', 'napkins',\n",
       "       ' asparagus'], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique items in the dataset\n",
    "unique_items = pd.unique(df.values.ravel('K'))\n",
    "unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp</th>\n",
       "      <th>burgers</th>\n",
       "      <th>chutney</th>\n",
       "      <th>turkey</th>\n",
       "      <th>mineral water</th>\n",
       "      <th>low fat yogurt</th>\n",
       "      <th>whole wheat pasta</th>\n",
       "      <th>soup</th>\n",
       "      <th>frozen vegetables</th>\n",
       "      <th>french fries</th>\n",
       "      <th>...</th>\n",
       "      <th>ketchup</th>\n",
       "      <th>cream</th>\n",
       "      <th>hand protein bar</th>\n",
       "      <th>body spray</th>\n",
       "      <th>oatmeal</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>water spray</th>\n",
       "      <th>tea</th>\n",
       "      <th>napkins</th>\n",
       "      <th>asparagus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [shrimp, burgers, chutney, turkey, mineral water, low fat yogurt, whole wheat pasta, soup, frozen vegetables, french fries, eggs, cookies, spaghetti, meatballs, red wine, rice, parmesan cheese, ground beef, sparkling water, herb & pepper, pickles, energy bar, fresh tuna, escalope, avocado, tomato sauce, clothes accessories, energy drink, chocolate, grated cheese, yogurt cake, mint, asparagus, champagne, ham, muffins, french wine, chicken, pasta, tomatoes, pancakes, frozen smoothie, carrots, yams, shallot, butter, light mayo, pepper, candy bars, cooking oil, milk, green tea, bug spray, oil, olive oil, salmon, cake, almonds, salt, strong cheese, hot dogs, pet food, whole wheat rice, antioxydant juice, honey, sandwich, salad, magazines, protein bar, mayonnaise, cider, burger sauce, green grapes, vegetables mix, bramble, nonfat milk, tomato juice, green beans, strawberries, eggplant, mushroom cream sauce, gums, cereals, flax seed, spinach, soda, dessert wine, corn, fresh bread, brownies, fromage blanc, chocolate bread, mashed potato, gluten free bar, cottage cheese, whole weat flour, chili, barbecue sauce, light cream, mint green tea, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 120 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the unique items as the column names\n",
    "transactions_data = pd.DataFrame(columns=unique_items)\n",
    "transactions_data.drop(columns= 0, inplace=True)\n",
    "transactions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the supermarket dataset\n",
    "# Each row is a transaction\n",
    "# If the item is present in the transaction, set the value as 1\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    transaction = df.iloc[i, :].values\n",
    "    # Remove the 0s from the transaction\n",
    "    transaction = transaction[transaction != 0]\n",
    "\n",
    "    # Set the value as 1 if the item is present in the transaction\n",
    "    for item in transaction:\n",
    "        transactions_data.at[i, item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp</th>\n",
       "      <th>burgers</th>\n",
       "      <th>chutney</th>\n",
       "      <th>turkey</th>\n",
       "      <th>mineral water</th>\n",
       "      <th>low fat yogurt</th>\n",
       "      <th>whole wheat pasta</th>\n",
       "      <th>soup</th>\n",
       "      <th>frozen vegetables</th>\n",
       "      <th>french fries</th>\n",
       "      <th>...</th>\n",
       "      <th>ketchup</th>\n",
       "      <th>cream</th>\n",
       "      <th>hand protein bar</th>\n",
       "      <th>body spray</th>\n",
       "      <th>oatmeal</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>water spray</th>\n",
       "      <th>tea</th>\n",
       "      <th>napkins</th>\n",
       "      <th>asparagus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  shrimp burgers chutney turkey mineral water low fat yogurt  \\\n",
       "0      1     NaN     NaN    NaN             1              1   \n",
       "1    NaN       1     NaN    NaN           NaN            NaN   \n",
       "2    NaN     NaN       1    NaN           NaN            NaN   \n",
       "3    NaN     NaN     NaN      1           NaN            NaN   \n",
       "4    NaN     NaN     NaN    NaN             1            NaN   \n",
       "\n",
       "  whole wheat pasta soup frozen vegetables french fries  ... ketchup cream  \\\n",
       "0               NaN  NaN               NaN          NaN  ...     NaN   NaN   \n",
       "1               NaN  NaN               NaN          NaN  ...     NaN   NaN   \n",
       "2               NaN  NaN               NaN          NaN  ...     NaN   NaN   \n",
       "3               NaN  NaN               NaN          NaN  ...     NaN   NaN   \n",
       "4               NaN  NaN               NaN          NaN  ...     NaN   NaN   \n",
       "\n",
       "  hand protein bar body spray oatmeal zucchini water spray  tea napkins  \\\n",
       "0              NaN        NaN     NaN      NaN         NaN  NaN     NaN   \n",
       "1              NaN        NaN     NaN      NaN         NaN  NaN     NaN   \n",
       "2              NaN        NaN     NaN      NaN         NaN  NaN     NaN   \n",
       "3              NaN        NaN     NaN      NaN         NaN  NaN     NaN   \n",
       "4              NaN        NaN     NaN      NaN         NaN  NaN     NaN   \n",
       "\n",
       "   asparagus  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrimp</th>\n",
       "      <th>burgers</th>\n",
       "      <th>chutney</th>\n",
       "      <th>turkey</th>\n",
       "      <th>mineral water</th>\n",
       "      <th>low fat yogurt</th>\n",
       "      <th>whole wheat pasta</th>\n",
       "      <th>soup</th>\n",
       "      <th>frozen vegetables</th>\n",
       "      <th>french fries</th>\n",
       "      <th>...</th>\n",
       "      <th>ketchup</th>\n",
       "      <th>cream</th>\n",
       "      <th>hand protein bar</th>\n",
       "      <th>body spray</th>\n",
       "      <th>oatmeal</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>water spray</th>\n",
       "      <th>tea</th>\n",
       "      <th>napkins</th>\n",
       "      <th>asparagus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shrimp  burgers  chutney  turkey  mineral water  low fat yogurt  \\\n",
       "0       1        0        0       0              1               1   \n",
       "1       0        1        0       0              0               0   \n",
       "2       0        0        1       0              0               0   \n",
       "3       0        0        0       1              0               0   \n",
       "4       0        0        0       0              1               0   \n",
       "\n",
       "   whole wheat pasta  soup  frozen vegetables  french fries  ...  ketchup  \\\n",
       "0                  0     0                  0             0  ...        0   \n",
       "1                  0     0                  0             0  ...        0   \n",
       "2                  0     0                  0             0  ...        0   \n",
       "3                  0     0                  0             0  ...        0   \n",
       "4                  0     0                  0             0  ...        0   \n",
       "\n",
       "   cream  hand protein bar  body spray  oatmeal  zucchini  water spray  tea  \\\n",
       "0      0                 0           0        0         0            0    0   \n",
       "1      0                 0           0        0         0            0    0   \n",
       "2      0                 0           0        0         0            0    0   \n",
       "3      0                 0           0        0         0            0    0   \n",
       "4      0                 0           0        0         0            0    0   \n",
       "\n",
       "   napkins   asparagus  \n",
       "0        0           0  \n",
       "1        0           0  \n",
       "2        0           0  \n",
       "3        0           0  \n",
       "4        0           0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_data.fillna(0, inplace=True)\n",
    "transactions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('shrimp',): 536, ('burgers',): 654, ('turkey',): 469, ('mineral water',): 1788, ('low fat yogurt',): 574, ('whole wheat pasta',): 221, ('soup',): 379, ('frozen vegetables',): 715, ('french fries',): 1282, ('eggs',): 1348, ('cookies',): 603, ('spaghetti',): 1306, ('meatballs',): 157, ('red wine',): 211, ('rice',): 141, ('parmesan cheese',): 149, ('ground beef',): 737, ('herb & pepper',): 371, ('energy bar',): 203, ('fresh tuna',): 167, ('escalope',): 595, ('avocado',): 250, ('tomato sauce',): 106, ('energy drink',): 200, ('chocolate',): 1229, ('grated cheese',): 393, ('yogurt cake',): 205, ('mint',): 131, ('champagne',): 351, ('ham',): 199, ('muffins',): 181, ('french wine',): 169, ('chicken',): 450, ('pasta',): 118, ('tomatoes',): 513, ('pancakes',): 713, ('frozen smoothie',): 475, ('carrots',): 115, ('butter',): 226, ('light mayo',): 204, ('pepper',): 199, ('cooking oil',): 383, ('milk',): 972, ('green tea',): 991, ('oil',): 173, ('olive oil',): 494, ('salmon',): 319, ('cake',): 608, ('almonds',): 153, ('hot dogs',): 243, ('whole wheat rice',): 439, ('honey',): 356, ('protein bar',): 139, ('vegetables mix',): 193, ('tomato juice',): 228, ('strawberries',): 160, ('mushroom cream sauce',): 143, ('gums',): 101, ('cereals',): 193, ('fresh bread',): 323, ('brownies',): 253, ('fromage blanc',): 102, ('cottage cheese',): 239, ('light cream',): 117, ('black tea',): 107, ('white wine',): 124}\n",
      "{'shrimp': 536, 'burgers': 654, 'turkey': 469, 'mineral water': 1788, 'low fat yogurt': 574, 'whole wheat pasta': 221, 'soup': 379, 'frozen vegetables': 715, 'french fries': 1282, 'eggs': 1348, 'cookies': 603, 'spaghetti': 1306, 'meatballs': 157, 'red wine': 211, 'rice': 141, 'parmesan cheese': 149, 'ground beef': 737, 'herb & pepper': 371, 'energy bar': 203, 'fresh tuna': 167, 'escalope': 595, 'avocado': 250, 'tomato sauce': 106, 'energy drink': 200, 'chocolate': 1229, 'grated cheese': 393, 'yogurt cake': 205, 'mint': 131, 'champagne': 351, 'ham': 199, 'muffins': 181, 'french wine': 169, 'chicken': 450, 'pasta': 118, 'tomatoes': 513, 'pancakes': 713, 'frozen smoothie': 475, 'carrots': 115, 'butter': 226, 'light mayo': 204, 'pepper': 199, 'cooking oil': 383, 'milk': 972, 'green tea': 991, 'oil': 173, 'olive oil': 494, 'salmon': 319, 'cake': 608, 'almonds': 153, 'hot dogs': 243, 'whole wheat rice': 439, 'honey': 356, 'protein bar': 139, 'vegetables mix': 193, 'tomato juice': 228, 'strawberries': 160, 'mushroom cream sauce': 143, 'gums': 101, 'cereals': 193, 'fresh bread': 323, 'brownies': 253, 'fromage blanc': 102, 'cottage cheese': 239, 'light cream': 117, 'black tea': 107, 'white wine': 124}\n",
      "{('shrimp',): 536, ('burgers',): 654, ('turkey',): 469, ('mineral water',): 1788, ('low fat yogurt',): 574, ('whole wheat pasta',): 221, ('soup',): 379, ('frozen vegetables',): 715, ('french fries',): 1282, ('eggs',): 1348, ('cookies',): 603, ('spaghetti',): 1306, ('meatballs',): 157, ('red wine',): 211, ('rice',): 141, ('parmesan cheese',): 149, ('ground beef',): 737, ('herb & pepper',): 371, ('energy bar',): 203, ('fresh tuna',): 167, ('escalope',): 595, ('avocado',): 250, ('tomato sauce',): 106, ('energy drink',): 200, ('chocolate',): 1229, ('grated cheese',): 393, ('yogurt cake',): 205, ('mint',): 131, ('champagne',): 351, ('ham',): 199, ('muffins',): 181, ('french wine',): 169, ('chicken',): 450, ('pasta',): 118, ('tomatoes',): 513, ('pancakes',): 713, ('frozen smoothie',): 475, ('carrots',): 115, ('butter',): 226, ('light mayo',): 204, ('pepper',): 199, ('cooking oil',): 383, ('milk',): 972, ('green tea',): 991, ('oil',): 173, ('olive oil',): 494, ('salmon',): 319, ('cake',): 608, ('almonds',): 153, ('hot dogs',): 243, ('whole wheat rice',): 439, ('honey',): 356, ('protein bar',): 139, ('vegetables mix',): 193, ('tomato juice',): 228, ('strawberries',): 160, ('mushroom cream sauce',): 143, ('gums',): 101, ('cereals',): 193, ('fresh bread',): 323, ('brownies',): 253, ('fromage blanc',): 102, ('cottage cheese',): 239, ('light cream',): 117, ('black tea',): 107, ('white wine',): 124}\n",
      "k:  2\n",
      "{('shrimp',): 536, ('burgers',): 654, ('turkey',): 469, ('mineral water',): 1788, ('low fat yogurt',): 574, ('whole wheat pasta',): 221, ('soup',): 379, ('frozen vegetables',): 715, ('french fries',): 1282, ('eggs',): 1348, ('cookies',): 603, ('spaghetti',): 1306, ('meatballs',): 157, ('red wine',): 211, ('rice',): 141, ('parmesan cheese',): 149, ('ground beef',): 737, ('herb & pepper',): 371, ('energy bar',): 203, ('fresh tuna',): 167, ('escalope',): 595, ('avocado',): 250, ('tomato sauce',): 106, ('energy drink',): 200, ('chocolate',): 1229, ('grated cheese',): 393, ('yogurt cake',): 205, ('mint',): 131, ('champagne',): 351, ('ham',): 199, ('muffins',): 181, ('french wine',): 169, ('chicken',): 450, ('pasta',): 118, ('tomatoes',): 513, ('pancakes',): 713, ('frozen smoothie',): 475, ('carrots',): 115, ('butter',): 226, ('light mayo',): 204, ('pepper',): 199, ('cooking oil',): 383, ('milk',): 972, ('green tea',): 991, ('oil',): 173, ('olive oil',): 494, ('salmon',): 319, ('cake',): 608, ('almonds',): 153, ('hot dogs',): 243, ('whole wheat rice',): 439, ('honey',): 356, ('protein bar',): 139, ('vegetables mix',): 193, ('tomato juice',): 228, ('strawberries',): 160, ('mushroom cream sauce',): 143, ('gums',): 101, ('cereals',): 193, ('fresh bread',): 323, ('brownies',): 253, ('fromage blanc',): 102, ('cottage cheese',): 239, ('light cream',): 117, ('black tea',): 107, ('white wine',): 124, ('shrimp', 'mineral water'): 177, ('shrimp', 'frozen vegetables'): 125, ('shrimp', 'eggs'): 106, ('shrimp', 'spaghetti'): 159, ('shrimp', 'chocolate'): 135, ('shrimp', 'milk'): 132, ('burgers', 'mineral water'): 183, ('burgers', 'french fries'): 165, ('burgers', 'eggs'): 216, ('burgers', 'spaghetti'): 161, ('burgers', 'chocolate'): 128, ('burgers', 'milk'): 134, ('burgers', 'green tea'): 131, ('turkey', 'mineral water'): 144, ('turkey', 'eggs'): 146, ('turkey', 'spaghetti'): 124, ('mineral water', 'low fat yogurt'): 180, ('mineral water', 'soup'): 173, ('mineral water', 'frozen vegetables'): 268, ('mineral water', 'french fries'): 253, ('mineral water', 'eggs'): 382, ('mineral water', 'spaghetti'): 448, ('mineral water', 'ground beef'): 307, ('mineral water', 'herb & pepper'): 128, ('mineral water', 'escalope'): 128, ('mineral water', 'chocolate'): 395, ('mineral water', 'grated cheese'): 131, ('mineral water', 'chicken'): 171, ('mineral water', 'tomatoes'): 183, ('mineral water', 'pancakes'): 253, ('mineral water', 'frozen smoothie'): 152, ('mineral water', 'cooking oil'): 151, ('mineral water', 'milk'): 360, ('mineral water', 'green tea'): 233, ('mineral water', 'olive oil'): 207, ('mineral water', 'salmon'): 128, ('mineral water', 'cake'): 206, ('mineral water', 'whole wheat rice'): 151, ('mineral water', 'honey'): 113, ('mineral water', 'fresh bread'): 100, ('low fat yogurt', 'french fries'): 100, ('low fat yogurt', 'eggs'): 126, ('low fat yogurt', 'spaghetti'): 114, ('low fat yogurt', 'chocolate'): 111, ('soup', 'spaghetti'): 107, ('soup', 'milk'): 114, ('frozen vegetables', 'french fries'): 143, ('frozen vegetables', 'eggs'): 163, ('frozen vegetables', 'spaghetti'): 209, ('frozen vegetables', 'ground beef'): 127, ('frozen vegetables', 'chocolate'): 172, ('frozen vegetables', 'tomatoes'): 121, ('frozen vegetables', 'pancakes'): 101, ('frozen vegetables', 'milk'): 177, ('frozen vegetables', 'green tea'): 108, ('french fries', 'eggs'): 273, ('french fries', 'cookies'): 100, ('french fries', 'spaghetti'): 207, ('french fries', 'ground beef'): 104, ('french fries', 'escalope'): 123, ('french fries', 'chocolate'): 258, ('french fries', 'pancakes'): 151, ('french fries', 'frozen smoothie'): 109, ('french fries', 'milk'): 178, ('french fries', 'green tea'): 214, ('french fries', 'cake'): 134, ('eggs', 'spaghetti'): 274, ('eggs', 'ground beef'): 150, ('eggs', 'chocolate'): 249, ('eggs', 'chicken'): 108, ('eggs', 'pancakes'): 163, ('eggs', 'milk'): 231, ('eggs', 'green tea'): 191, ('eggs', 'cake'): 143, ('spaghetti', 'ground beef'): 294, ('spaghetti', 'herb & pepper'): 122, ('spaghetti', 'escalope'): 105, ('spaghetti', 'chocolate'): 294, ('spaghetti', 'grated cheese'): 124, ('spaghetti', 'chicken'): 129, ('spaghetti', 'tomatoes'): 157, ('spaghetti', 'pancakes'): 189, ('spaghetti', 'frozen smoothie'): 117, ('spaghetti', 'cooking oil'): 119, ('spaghetti', 'milk'): 266, ('spaghetti', 'green tea'): 199, ('spaghetti', 'olive oil'): 172, ('spaghetti', 'salmon'): 101, ('spaghetti', 'cake'): 136, ('spaghetti', 'whole wheat rice'): 106, ('ground beef', 'herb & pepper'): 120, ('ground beef', 'chocolate'): 173, ('ground beef', 'pancakes'): 109, ('ground beef', 'milk'): 165, ('ground beef', 'green tea'): 111, ('ground beef', 'olive oil'): 106, ('escalope', 'chocolate'): 132, ('chocolate', 'chicken'): 110, ('chocolate', 'tomatoes'): 105, ('chocolate', 'pancakes'): 149, ('chocolate', 'frozen smoothie'): 112, ('chocolate', 'cooking oil'): 102, ('chocolate', 'milk'): 241, ('chocolate', 'green tea'): 176, ('chocolate', 'olive oil'): 123, ('chocolate', 'cake'): 102, ('chicken', 'milk'): 111, ('tomatoes', 'milk'): 105, ('pancakes', 'milk'): 124, ('pancakes', 'green tea'): 123, ('frozen smoothie', 'milk'): 107, ('milk', 'green tea'): 132, ('milk', 'olive oil'): 128, ('milk', 'cake'): 100, ('green tea', 'cake'): 106}\n",
      "k:  3\n",
      "{('shrimp',): 536, ('burgers',): 654, ('turkey',): 469, ('mineral water',): 1788, ('low fat yogurt',): 574, ('whole wheat pasta',): 221, ('soup',): 379, ('frozen vegetables',): 715, ('french fries',): 1282, ('eggs',): 1348, ('cookies',): 603, ('spaghetti',): 1306, ('meatballs',): 157, ('red wine',): 211, ('rice',): 141, ('parmesan cheese',): 149, ('ground beef',): 737, ('herb & pepper',): 371, ('energy bar',): 203, ('fresh tuna',): 167, ('escalope',): 595, ('avocado',): 250, ('tomato sauce',): 106, ('energy drink',): 200, ('chocolate',): 1229, ('grated cheese',): 393, ('yogurt cake',): 205, ('mint',): 131, ('champagne',): 351, ('ham',): 199, ('muffins',): 181, ('french wine',): 169, ('chicken',): 450, ('pasta',): 118, ('tomatoes',): 513, ('pancakes',): 713, ('frozen smoothie',): 475, ('carrots',): 115, ('butter',): 226, ('light mayo',): 204, ('pepper',): 199, ('cooking oil',): 383, ('milk',): 972, ('green tea',): 991, ('oil',): 173, ('olive oil',): 494, ('salmon',): 319, ('cake',): 608, ('almonds',): 153, ('hot dogs',): 243, ('whole wheat rice',): 439, ('honey',): 356, ('protein bar',): 139, ('vegetables mix',): 193, ('tomato juice',): 228, ('strawberries',): 160, ('mushroom cream sauce',): 143, ('gums',): 101, ('cereals',): 193, ('fresh bread',): 323, ('brownies',): 253, ('fromage blanc',): 102, ('cottage cheese',): 239, ('light cream',): 117, ('black tea',): 107, ('white wine',): 124, ('shrimp', 'mineral water'): 177, ('shrimp', 'frozen vegetables'): 125, ('shrimp', 'eggs'): 106, ('shrimp', 'spaghetti'): 159, ('shrimp', 'chocolate'): 135, ('shrimp', 'milk'): 132, ('burgers', 'mineral water'): 183, ('burgers', 'french fries'): 165, ('burgers', 'eggs'): 216, ('burgers', 'spaghetti'): 161, ('burgers', 'chocolate'): 128, ('burgers', 'milk'): 134, ('burgers', 'green tea'): 131, ('turkey', 'mineral water'): 144, ('turkey', 'eggs'): 146, ('turkey', 'spaghetti'): 124, ('mineral water', 'low fat yogurt'): 180, ('mineral water', 'soup'): 173, ('mineral water', 'frozen vegetables'): 268, ('mineral water', 'french fries'): 253, ('mineral water', 'eggs'): 382, ('mineral water', 'spaghetti'): 448, ('mineral water', 'ground beef'): 307, ('mineral water', 'herb & pepper'): 128, ('mineral water', 'escalope'): 128, ('mineral water', 'chocolate'): 395, ('mineral water', 'grated cheese'): 131, ('mineral water', 'chicken'): 171, ('mineral water', 'tomatoes'): 183, ('mineral water', 'pancakes'): 253, ('mineral water', 'frozen smoothie'): 152, ('mineral water', 'cooking oil'): 151, ('mineral water', 'milk'): 360, ('mineral water', 'green tea'): 233, ('mineral water', 'olive oil'): 207, ('mineral water', 'salmon'): 128, ('mineral water', 'cake'): 206, ('mineral water', 'whole wheat rice'): 151, ('mineral water', 'honey'): 113, ('mineral water', 'fresh bread'): 100, ('low fat yogurt', 'french fries'): 100, ('low fat yogurt', 'eggs'): 126, ('low fat yogurt', 'spaghetti'): 114, ('low fat yogurt', 'chocolate'): 111, ('soup', 'spaghetti'): 107, ('soup', 'milk'): 114, ('frozen vegetables', 'french fries'): 143, ('frozen vegetables', 'eggs'): 163, ('frozen vegetables', 'spaghetti'): 209, ('frozen vegetables', 'ground beef'): 127, ('frozen vegetables', 'chocolate'): 172, ('frozen vegetables', 'tomatoes'): 121, ('frozen vegetables', 'pancakes'): 101, ('frozen vegetables', 'milk'): 177, ('frozen vegetables', 'green tea'): 108, ('french fries', 'eggs'): 273, ('french fries', 'cookies'): 100, ('french fries', 'spaghetti'): 207, ('french fries', 'ground beef'): 104, ('french fries', 'escalope'): 123, ('french fries', 'chocolate'): 258, ('french fries', 'pancakes'): 151, ('french fries', 'frozen smoothie'): 109, ('french fries', 'milk'): 178, ('french fries', 'green tea'): 214, ('french fries', 'cake'): 134, ('eggs', 'spaghetti'): 274, ('eggs', 'ground beef'): 150, ('eggs', 'chocolate'): 249, ('eggs', 'chicken'): 108, ('eggs', 'pancakes'): 163, ('eggs', 'milk'): 231, ('eggs', 'green tea'): 191, ('eggs', 'cake'): 143, ('spaghetti', 'ground beef'): 294, ('spaghetti', 'herb & pepper'): 122, ('spaghetti', 'escalope'): 105, ('spaghetti', 'chocolate'): 294, ('spaghetti', 'grated cheese'): 124, ('spaghetti', 'chicken'): 129, ('spaghetti', 'tomatoes'): 157, ('spaghetti', 'pancakes'): 189, ('spaghetti', 'frozen smoothie'): 117, ('spaghetti', 'cooking oil'): 119, ('spaghetti', 'milk'): 266, ('spaghetti', 'green tea'): 199, ('spaghetti', 'olive oil'): 172, ('spaghetti', 'salmon'): 101, ('spaghetti', 'cake'): 136, ('spaghetti', 'whole wheat rice'): 106, ('ground beef', 'herb & pepper'): 120, ('ground beef', 'chocolate'): 173, ('ground beef', 'pancakes'): 109, ('ground beef', 'milk'): 165, ('ground beef', 'green tea'): 111, ('ground beef', 'olive oil'): 106, ('escalope', 'chocolate'): 132, ('chocolate', 'chicken'): 110, ('chocolate', 'tomatoes'): 105, ('chocolate', 'pancakes'): 149, ('chocolate', 'frozen smoothie'): 112, ('chocolate', 'cooking oil'): 102, ('chocolate', 'milk'): 241, ('chocolate', 'green tea'): 176, ('chocolate', 'olive oil'): 123, ('chocolate', 'cake'): 102, ('chicken', 'milk'): 111, ('tomatoes', 'milk'): 105, ('pancakes', 'milk'): 124, ('pancakes', 'green tea'): 123, ('frozen smoothie', 'milk'): 107, ('milk', 'green tea'): 132, ('milk', 'olive oil'): 128, ('milk', 'cake'): 100, ('green tea', 'cake'): 106, ('mineral water', 'eggs', 'spaghetti'): 107, ('mineral water', 'eggs', 'chocolate'): 101, ('mineral water', 'spaghetti', 'ground beef'): 128, ('mineral water', 'spaghetti', 'chocolate'): 119, ('mineral water', 'spaghetti', 'milk'): 118, ('mineral water', 'chocolate', 'milk'): 105}\n",
      "k:  4\n"
     ]
    }
   ],
   "source": [
    "combined_freq_itemsets, rules = my_apriori(transactions_data, 100, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined frequent itemsets:  {('shrimp',): 536, ('burgers',): 654, ('turkey',): 469, ('mineral water',): 1788, ('low fat yogurt',): 574, ('whole wheat pasta',): 221, ('soup',): 379, ('frozen vegetables',): 715, ('french fries',): 1282, ('eggs',): 1348, ('cookies',): 603, ('spaghetti',): 1306, ('meatballs',): 157, ('red wine',): 211, ('rice',): 141, ('parmesan cheese',): 149, ('ground beef',): 737, ('herb & pepper',): 371, ('energy bar',): 203, ('fresh tuna',): 167, ('escalope',): 595, ('avocado',): 250, ('tomato sauce',): 106, ('energy drink',): 200, ('chocolate',): 1229, ('grated cheese',): 393, ('yogurt cake',): 205, ('mint',): 131, ('champagne',): 351, ('ham',): 199, ('muffins',): 181, ('french wine',): 169, ('chicken',): 450, ('pasta',): 118, ('tomatoes',): 513, ('pancakes',): 713, ('frozen smoothie',): 475, ('carrots',): 115, ('butter',): 226, ('light mayo',): 204, ('pepper',): 199, ('cooking oil',): 383, ('milk',): 972, ('green tea',): 991, ('oil',): 173, ('olive oil',): 494, ('salmon',): 319, ('cake',): 608, ('almonds',): 153, ('hot dogs',): 243, ('whole wheat rice',): 439, ('honey',): 356, ('protein bar',): 139, ('vegetables mix',): 193, ('tomato juice',): 228, ('strawberries',): 160, ('mushroom cream sauce',): 143, ('gums',): 101, ('cereals',): 193, ('fresh bread',): 323, ('brownies',): 253, ('fromage blanc',): 102, ('cottage cheese',): 239, ('light cream',): 117, ('black tea',): 107, ('white wine',): 124, ('shrimp', 'mineral water'): 177, ('shrimp', 'frozen vegetables'): 125, ('shrimp', 'eggs'): 106, ('shrimp', 'spaghetti'): 159, ('shrimp', 'chocolate'): 135, ('shrimp', 'milk'): 132, ('burgers', 'mineral water'): 183, ('burgers', 'french fries'): 165, ('burgers', 'eggs'): 216, ('burgers', 'spaghetti'): 161, ('burgers', 'chocolate'): 128, ('burgers', 'milk'): 134, ('burgers', 'green tea'): 131, ('turkey', 'mineral water'): 144, ('turkey', 'eggs'): 146, ('turkey', 'spaghetti'): 124, ('mineral water', 'low fat yogurt'): 180, ('mineral water', 'soup'): 173, ('mineral water', 'frozen vegetables'): 268, ('mineral water', 'french fries'): 253, ('mineral water', 'eggs'): 382, ('mineral water', 'spaghetti'): 448, ('mineral water', 'ground beef'): 307, ('mineral water', 'herb & pepper'): 128, ('mineral water', 'escalope'): 128, ('mineral water', 'chocolate'): 395, ('mineral water', 'grated cheese'): 131, ('mineral water', 'chicken'): 171, ('mineral water', 'tomatoes'): 183, ('mineral water', 'pancakes'): 253, ('mineral water', 'frozen smoothie'): 152, ('mineral water', 'cooking oil'): 151, ('mineral water', 'milk'): 360, ('mineral water', 'green tea'): 233, ('mineral water', 'olive oil'): 207, ('mineral water', 'salmon'): 128, ('mineral water', 'cake'): 206, ('mineral water', 'whole wheat rice'): 151, ('mineral water', 'honey'): 113, ('mineral water', 'fresh bread'): 100, ('low fat yogurt', 'french fries'): 100, ('low fat yogurt', 'eggs'): 126, ('low fat yogurt', 'spaghetti'): 114, ('low fat yogurt', 'chocolate'): 111, ('soup', 'spaghetti'): 107, ('soup', 'milk'): 114, ('frozen vegetables', 'french fries'): 143, ('frozen vegetables', 'eggs'): 163, ('frozen vegetables', 'spaghetti'): 209, ('frozen vegetables', 'ground beef'): 127, ('frozen vegetables', 'chocolate'): 172, ('frozen vegetables', 'tomatoes'): 121, ('frozen vegetables', 'pancakes'): 101, ('frozen vegetables', 'milk'): 177, ('frozen vegetables', 'green tea'): 108, ('french fries', 'eggs'): 273, ('french fries', 'cookies'): 100, ('french fries', 'spaghetti'): 207, ('french fries', 'ground beef'): 104, ('french fries', 'escalope'): 123, ('french fries', 'chocolate'): 258, ('french fries', 'pancakes'): 151, ('french fries', 'frozen smoothie'): 109, ('french fries', 'milk'): 178, ('french fries', 'green tea'): 214, ('french fries', 'cake'): 134, ('eggs', 'spaghetti'): 274, ('eggs', 'ground beef'): 150, ('eggs', 'chocolate'): 249, ('eggs', 'chicken'): 108, ('eggs', 'pancakes'): 163, ('eggs', 'milk'): 231, ('eggs', 'green tea'): 191, ('eggs', 'cake'): 143, ('spaghetti', 'ground beef'): 294, ('spaghetti', 'herb & pepper'): 122, ('spaghetti', 'escalope'): 105, ('spaghetti', 'chocolate'): 294, ('spaghetti', 'grated cheese'): 124, ('spaghetti', 'chicken'): 129, ('spaghetti', 'tomatoes'): 157, ('spaghetti', 'pancakes'): 189, ('spaghetti', 'frozen smoothie'): 117, ('spaghetti', 'cooking oil'): 119, ('spaghetti', 'milk'): 266, ('spaghetti', 'green tea'): 199, ('spaghetti', 'olive oil'): 172, ('spaghetti', 'salmon'): 101, ('spaghetti', 'cake'): 136, ('spaghetti', 'whole wheat rice'): 106, ('ground beef', 'herb & pepper'): 120, ('ground beef', 'chocolate'): 173, ('ground beef', 'pancakes'): 109, ('ground beef', 'milk'): 165, ('ground beef', 'green tea'): 111, ('ground beef', 'olive oil'): 106, ('escalope', 'chocolate'): 132, ('chocolate', 'chicken'): 110, ('chocolate', 'tomatoes'): 105, ('chocolate', 'pancakes'): 149, ('chocolate', 'frozen smoothie'): 112, ('chocolate', 'cooking oil'): 102, ('chocolate', 'milk'): 241, ('chocolate', 'green tea'): 176, ('chocolate', 'olive oil'): 123, ('chocolate', 'cake'): 102, ('chicken', 'milk'): 111, ('tomatoes', 'milk'): 105, ('pancakes', 'milk'): 124, ('pancakes', 'green tea'): 123, ('frozen smoothie', 'milk'): 107, ('milk', 'green tea'): 132, ('milk', 'olive oil'): 128, ('milk', 'cake'): 100, ('green tea', 'cake'): 106, ('mineral water', 'eggs', 'spaghetti'): 107, ('mineral water', 'eggs', 'chocolate'): 101, ('mineral water', 'spaghetti', 'ground beef'): 128, ('mineral water', 'spaghetti', 'chocolate'): 119, ('mineral water', 'spaghetti', 'milk'): 118, ('mineral water', 'chocolate', 'milk'): 105}\n"
     ]
    }
   ],
   "source": [
    "print('combined frequent itemsets: ', combined_freq_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule  1 : antecedent -> consequent:  ['soup'] ->  ['mineral water'] confidence:  0.45646437994722955\n",
      "Rule  2 : antecedent -> consequent:  ['ground beef'] ->  ['mineral water'] confidence:  0.41655359565807326\n",
      "Rule  3 : antecedent -> consequent:  ['olive oil'] ->  ['mineral water'] confidence:  0.4190283400809717\n",
      "Rule  4 : antecedent -> consequent:  ['salmon'] ->  ['mineral water'] confidence:  0.4012539184952978\n",
      "Rule  5 : antecedent -> consequent:  ['eggs', 'chocolate'] ->  ['mineral water'] confidence:  0.40562248995983935\n",
      "Rule  6 : antecedent -> consequent:  ['mineral water', 'ground beef'] ->  ['spaghetti'] confidence:  0.4169381107491857\n",
      "Rule  7 : antecedent -> consequent:  ['spaghetti', 'ground beef'] ->  ['mineral water'] confidence:  0.43537414965986393\n",
      "Rule  8 : antecedent -> consequent:  ['spaghetti', 'chocolate'] ->  ['mineral water'] confidence:  0.40476190476190477\n",
      "Rule  9 : antecedent -> consequent:  ['spaghetti', 'milk'] ->  ['mineral water'] confidence:  0.44360902255639095\n",
      "Rule  10 : antecedent -> consequent:  ['chocolate', 'milk'] ->  ['mineral water'] confidence:  0.43568464730290457\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for key, item in rules.items():\n",
    "    for i in range(1, len(key)):\n",
    "        antecedent = key[:i]\n",
    "        consequent = key[i:]\n",
    "        print('Rule ', index, ': antecedent -> consequent: ', list(sum(antecedent, ())), '-> ', list(sum(consequent, ())), 'confidence: ', item)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Verify with official Apriori library </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7501, 120)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tengwei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071457</td>\n",
       "      <td>(shrimp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087188</td>\n",
       "      <td>(burgers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062525</td>\n",
       "      <td>(turkey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238368</td>\n",
       "      <td>(mineral water)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076523</td>\n",
       "      <td>(low fat yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.013465</td>\n",
       "      <td>(eggs, mineral water, chocolate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.017064</td>\n",
       "      <td>(ground beef, spaghetti, mineral water)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.015865</td>\n",
       "      <td>(spaghetti, mineral water, chocolate)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.015731</td>\n",
       "      <td>(spaghetti, mineral water, milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.013998</td>\n",
       "      <td>(chocolate, mineral water, milk)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support                                 itemsets\n",
       "0    0.071457                                 (shrimp)\n",
       "1    0.087188                                (burgers)\n",
       "2    0.062525                                 (turkey)\n",
       "3    0.238368                          (mineral water)\n",
       "4    0.076523                         (low fat yogurt)\n",
       "..        ...                                      ...\n",
       "182  0.013465         (eggs, mineral water, chocolate)\n",
       "183  0.017064  (ground beef, spaghetti, mineral water)\n",
       "184  0.015865    (spaghetti, mineral water, chocolate)\n",
       "185  0.015731         (spaghetti, mineral water, milk)\n",
       "186  0.013998         (chocolate, mineral water, milk)\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_items = apriori(transactions_data, min_support=0.0133, use_colnames=True)\n",
    "freq_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(soup)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.050527</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>0.456464</td>\n",
       "      <td>1.914955</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>1.401255</td>\n",
       "      <td>0.503221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ground beef)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.098254</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.040928</td>\n",
       "      <td>0.416554</td>\n",
       "      <td>1.747522</td>\n",
       "      <td>0.017507</td>\n",
       "      <td>1.305401</td>\n",
       "      <td>0.474369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(olive oil)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.065858</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.027596</td>\n",
       "      <td>0.419028</td>\n",
       "      <td>1.757904</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>1.310962</td>\n",
       "      <td>0.461536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(salmon)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.401254</td>\n",
       "      <td>1.683336</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>1.272045</td>\n",
       "      <td>0.423972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(eggs, chocolate)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.033196</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>0.405622</td>\n",
       "      <td>1.701663</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>1.281394</td>\n",
       "      <td>0.426498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(ground beef, spaghetti)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.435374</td>\n",
       "      <td>1.826477</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>1.348914</td>\n",
       "      <td>0.470957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(ground beef, mineral water)</td>\n",
       "      <td>(spaghetti)</td>\n",
       "      <td>0.040928</td>\n",
       "      <td>0.174110</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.416938</td>\n",
       "      <td>2.394681</td>\n",
       "      <td>0.009938</td>\n",
       "      <td>1.416470</td>\n",
       "      <td>0.607262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(spaghetti, chocolate)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>1.698053</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>1.279541</td>\n",
       "      <td>0.427860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(spaghetti, milk)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.035462</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.443609</td>\n",
       "      <td>1.861024</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>1.368879</td>\n",
       "      <td>0.479672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(milk, chocolate)</td>\n",
       "      <td>(mineral water)</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.238368</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.435685</td>\n",
       "      <td>1.827780</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>1.349656</td>\n",
       "      <td>0.467922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    antecedents      consequents  antecedent support  \\\n",
       "0                        (soup)  (mineral water)            0.050527   \n",
       "1                 (ground beef)  (mineral water)            0.098254   \n",
       "2                   (olive oil)  (mineral water)            0.065858   \n",
       "3                      (salmon)  (mineral water)            0.042528   \n",
       "4             (eggs, chocolate)  (mineral water)            0.033196   \n",
       "5      (ground beef, spaghetti)  (mineral water)            0.039195   \n",
       "6  (ground beef, mineral water)      (spaghetti)            0.040928   \n",
       "7        (spaghetti, chocolate)  (mineral water)            0.039195   \n",
       "8             (spaghetti, milk)  (mineral water)            0.035462   \n",
       "9             (milk, chocolate)  (mineral water)            0.032129   \n",
       "\n",
       "   consequent support   support  confidence      lift  leverage  conviction  \\\n",
       "0            0.238368  0.023064    0.456464  1.914955  0.011020    1.401255   \n",
       "1            0.238368  0.040928    0.416554  1.747522  0.017507    1.305401   \n",
       "2            0.238368  0.027596    0.419028  1.757904  0.011898    1.310962   \n",
       "3            0.238368  0.017064    0.401254  1.683336  0.006927    1.272045   \n",
       "4            0.238368  0.013465    0.405622  1.701663  0.005552    1.281394   \n",
       "5            0.238368  0.017064    0.435374  1.826477  0.007722    1.348914   \n",
       "6            0.174110  0.017064    0.416938  2.394681  0.009938    1.416470   \n",
       "7            0.238368  0.015865    0.404762  1.698053  0.006522    1.279541   \n",
       "8            0.238368  0.015731    0.443609  1.861024  0.007278    1.368879   \n",
       "9            0.238368  0.013998    0.435685  1.827780  0.006340    1.349656   \n",
       "\n",
       "   zhangs_metric  \n",
       "0       0.503221  \n",
       "1       0.474369  \n",
       "2       0.461536  \n",
       "3       0.423972  \n",
       "4       0.426498  \n",
       "5       0.470957  \n",
       "6       0.607262  \n",
       "7       0.427860  \n",
       "8       0.479672  \n",
       "9       0.467922  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = association_rules(freq_items, metric='confidence', min_threshold=0.4)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Titanic dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survival_df = pd.read_csv('titanic/gender_submission.csv')\n",
    "survival_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titanic_df = pd.read_csv('titanic/train.csv')\n",
    "test_titanic_df = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age Embarked\n",
       "0         0       3    male  22.0        S\n",
       "1         1       1  female  38.0        C\n",
       "2         1       3  female  26.0        S\n",
       "3         1       1  female  35.0        S\n",
       "4         0       3    male  35.0        S"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that are not required\n",
    "train_titanic_df.drop(columns=['PassengerId', 'Name','SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin'], inplace=True)\n",
    "train_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex    Age Embarked\n",
       "0         0       3    male  Adult        S\n",
       "1         1       1  female  Adult        C\n",
       "2         1       3  female  Adult        S\n",
       "3         1       1  female  Adult        S\n",
       "4         0       3    male  Adult        S"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorise the Age column\n",
    "# Age 21 and below is a Child\n",
    "# Age between 21 and 55 is an Adult\n",
    "# Age above 55 is an Elderly\n",
    "train_titanic_df['Age'] = pd.cut(train_titanic_df['Age'], bins=[0, 21, 55, 80], labels=['Child', 'Adult', 'Elderly'])\n",
    "train_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age_Child</th>\n",
       "      <th>Age_Adult</th>\n",
       "      <th>Age_Elderly</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex_female  Sex_male  Age_Child  Age_Adult  Age_Elderly  \\\n",
       "0         0       3           0         1          0          1            0   \n",
       "1         1       1           1         0          0          1            0   \n",
       "2         1       3           1         0          0          1            0   \n",
       "3         1       1           1         0          0          1            0   \n",
       "4         0       3           0         1          0          1            0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert into one hot encoding\n",
    "train_titanic_df = pd.get_dummies(train_titanic_df)\n",
    "train_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age_Child</th>\n",
       "      <th>Age_Adult</th>\n",
       "      <th>Age_Elderly</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex_female  Sex_male  Age_Child  Age_Adult  Age_Elderly  \\\n",
       "0         0           0         1          0          1            0   \n",
       "1         1           1         0          0          1            0   \n",
       "2         1           1         0          0          1            0   \n",
       "3         1           1         0          0          1            0   \n",
       "4         0           0         1          0          1            0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "0           0           0           1         0         0         1  \n",
       "1           1           0           0         1         0         0  \n",
       "2           0           0           1         0         0         1  \n",
       "3           0           0           1         1         0         0  \n",
       "4           0           0           1         0         0         1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converet Pclass into one hot encoding\n",
    "train_titanic_df = pd.get_dummies(train_titanic_df, columns=['Pclass'])\n",
    "train_titanic_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Survived</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Survived  count\n",
       "0         0           1         0     81\n",
       "1         0           1         1    233\n",
       "2         1           0         0    468\n",
       "3         1           0         1    109"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titanic_df.groupby(['Sex_male', 'Sex_female', 'Survived']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_titanic_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sex_female',)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination = ('Survived', 'Sex_female')\n",
    "target = ('Survived',)\n",
    "tuple(set(combination) - set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491}\n",
      "{'Survived': 342, 'Sex_female': 314, 'Sex_male': 577, 'Age_Child': 204, 'Age_Adult': 470, 'Age_Elderly': 40, 'Embarked_C': 168, 'Embarked_Q': 77, 'Embarked_S': 644, 'Pclass_1': 216, 'Pclass_2': 184, 'Pclass_3': 491}\n",
      "{('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491}\n",
      "k:  2\n",
      "{('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491, ('Survived', 'Sex_female'): 233, ('Survived', 'Sex_male'): 109, ('Survived', 'Age_Child'): 87, ('Survived', 'Age_Adult'): 191, ('Survived', 'Embarked_C'): 93, ('Survived', 'Embarked_Q'): 30, ('Survived', 'Embarked_S'): 217, ('Survived', 'Pclass_1'): 136, ('Survived', 'Pclass_2'): 87, ('Survived', 'Pclass_3'): 119, ('Sex_female', 'Age_Child'): 84, ('Sex_female', 'Age_Adult'): 168, ('Sex_female', 'Embarked_C'): 73, ('Sex_female', 'Embarked_Q'): 36, ('Sex_female', 'Embarked_S'): 203, ('Sex_female', 'Pclass_1'): 94, ('Sex_female', 'Pclass_2'): 76, ('Sex_female', 'Pclass_3'): 144, ('Sex_male', 'Age_Child'): 120, ('Sex_male', 'Age_Adult'): 302, ('Sex_male', 'Age_Elderly'): 31, ('Sex_male', 'Embarked_C'): 95, ('Sex_male', 'Embarked_Q'): 41, ('Sex_male', 'Embarked_S'): 441, ('Sex_male', 'Pclass_1'): 122, ('Sex_male', 'Pclass_2'): 108, ('Sex_male', 'Pclass_3'): 347, ('Age_Child', 'Embarked_C'): 33, ('Age_Child', 'Embarked_S'): 159, ('Age_Child', 'Pclass_2'): 39, ('Age_Child', 'Pclass_3'): 141, ('Age_Adult', 'Embarked_C'): 86, ('Age_Adult', 'Embarked_S'): 370, ('Age_Adult', 'Pclass_1'): 136, ('Age_Adult', 'Pclass_2'): 127, ('Age_Adult', 'Pclass_3'): 207, ('Embarked_C', 'Pclass_1'): 85, ('Embarked_C', 'Pclass_3'): 66, ('Embarked_Q', 'Pclass_3'): 72, ('Embarked_S', 'Pclass_1'): 127, ('Embarked_S', 'Pclass_2'): 164, ('Embarked_S', 'Pclass_3'): 353}\n",
      "k:  3\n",
      "{('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491, ('Survived', 'Sex_female'): 233, ('Survived', 'Sex_male'): 109, ('Survived', 'Age_Child'): 87, ('Survived', 'Age_Adult'): 191, ('Survived', 'Embarked_C'): 93, ('Survived', 'Embarked_Q'): 30, ('Survived', 'Embarked_S'): 217, ('Survived', 'Pclass_1'): 136, ('Survived', 'Pclass_2'): 87, ('Survived', 'Pclass_3'): 119, ('Sex_female', 'Age_Child'): 84, ('Sex_female', 'Age_Adult'): 168, ('Sex_female', 'Embarked_C'): 73, ('Sex_female', 'Embarked_Q'): 36, ('Sex_female', 'Embarked_S'): 203, ('Sex_female', 'Pclass_1'): 94, ('Sex_female', 'Pclass_2'): 76, ('Sex_female', 'Pclass_3'): 144, ('Sex_male', 'Age_Child'): 120, ('Sex_male', 'Age_Adult'): 302, ('Sex_male', 'Age_Elderly'): 31, ('Sex_male', 'Embarked_C'): 95, ('Sex_male', 'Embarked_Q'): 41, ('Sex_male', 'Embarked_S'): 441, ('Sex_male', 'Pclass_1'): 122, ('Sex_male', 'Pclass_2'): 108, ('Sex_male', 'Pclass_3'): 347, ('Age_Child', 'Embarked_C'): 33, ('Age_Child', 'Embarked_S'): 159, ('Age_Child', 'Pclass_2'): 39, ('Age_Child', 'Pclass_3'): 141, ('Age_Adult', 'Embarked_C'): 86, ('Age_Adult', 'Embarked_S'): 370, ('Age_Adult', 'Pclass_1'): 136, ('Age_Adult', 'Pclass_2'): 127, ('Age_Adult', 'Pclass_3'): 207, ('Embarked_C', 'Pclass_1'): 85, ('Embarked_C', 'Pclass_3'): 66, ('Embarked_Q', 'Pclass_3'): 72, ('Embarked_S', 'Pclass_1'): 127, ('Embarked_S', 'Pclass_2'): 164, ('Embarked_S', 'Pclass_3'): 353, ('Survived', 'Sex_female', 'Age_Child'): 57, ('Survived', 'Sex_female', 'Age_Adult'): 132, ('Survived', 'Sex_female', 'Embarked_C'): 64, ('Survived', 'Sex_female', 'Embarked_S'): 140, ('Survived', 'Sex_female', 'Pclass_1'): 91, ('Survived', 'Sex_female', 'Pclass_2'): 70, ('Survived', 'Sex_female', 'Pclass_3'): 72, ('Survived', 'Sex_male', 'Age_Child'): 30, ('Survived', 'Sex_male', 'Age_Adult'): 59, ('Survived', 'Sex_male', 'Embarked_S'): 77, ('Survived', 'Sex_male', 'Pclass_1'): 45, ('Survived', 'Sex_male', 'Pclass_3'): 47, ('Survived', 'Age_Child', 'Embarked_S'): 59, ('Survived', 'Age_Child', 'Pclass_3'): 41, ('Survived', 'Age_Adult', 'Embarked_C'): 50, ('Survived', 'Age_Adult', 'Embarked_S'): 136, ('Survived', 'Age_Adult', 'Pclass_1'): 93, ('Survived', 'Age_Adult', 'Pclass_2'): 55, ('Survived', 'Age_Adult', 'Pclass_3'): 43, ('Survived', 'Embarked_C', 'Pclass_1'): 59, ('Survived', 'Embarked_S', 'Pclass_1'): 74, ('Survived', 'Embarked_S', 'Pclass_2'): 76, ('Survived', 'Embarked_S', 'Pclass_3'): 67, ('Sex_female', 'Age_Child', 'Embarked_S'): 56, ('Sex_female', 'Age_Child', 'Pclass_3'): 51, ('Sex_female', 'Age_Adult', 'Embarked_C'): 36, ('Sex_female', 'Age_Adult', 'Embarked_S'): 125, ('Sex_female', 'Age_Adult', 'Pclass_1'): 62, ('Sex_female', 'Age_Adult', 'Pclass_2'): 56, ('Sex_female', 'Age_Adult', 'Pclass_3'): 50, ('Sex_female', 'Embarked_C', 'Pclass_1'): 43, ('Sex_female', 'Embarked_Q', 'Pclass_3'): 33, ('Sex_female', 'Embarked_S', 'Pclass_1'): 48, ('Sex_female', 'Embarked_S', 'Pclass_2'): 67, ('Sex_female', 'Embarked_S', 'Pclass_3'): 88, ('Sex_male', 'Age_Child', 'Embarked_S'): 103, ('Sex_male', 'Age_Child', 'Pclass_3'): 90, ('Sex_male', 'Age_Adult', 'Embarked_C'): 50, ('Sex_male', 'Age_Adult', 'Embarked_S'): 245, ('Sex_male', 'Age_Adult', 'Pclass_1'): 74, ('Sex_male', 'Age_Adult', 'Pclass_2'): 71, ('Sex_male', 'Age_Adult', 'Pclass_3'): 157, ('Sex_male', 'Embarked_C', 'Pclass_1'): 42, ('Sex_male', 'Embarked_C', 'Pclass_3'): 43, ('Sex_male', 'Embarked_Q', 'Pclass_3'): 39, ('Sex_male', 'Embarked_S', 'Pclass_1'): 79, ('Sex_male', 'Embarked_S', 'Pclass_2'): 97, ('Sex_male', 'Embarked_S', 'Pclass_3'): 265, ('Age_Child', 'Embarked_S', 'Pclass_2'): 35, ('Age_Child', 'Embarked_S', 'Pclass_3'): 108, ('Age_Adult', 'Embarked_C', 'Pclass_1'): 55, ('Age_Adult', 'Embarked_S', 'Pclass_1'): 78, ('Age_Adult', 'Embarked_S', 'Pclass_2'): 115, ('Age_Adult', 'Embarked_S', 'Pclass_3'): 177}\n",
      "k:  4\n",
      "{('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491, ('Survived', 'Sex_female'): 233, ('Survived', 'Sex_male'): 109, ('Survived', 'Age_Child'): 87, ('Survived', 'Age_Adult'): 191, ('Survived', 'Embarked_C'): 93, ('Survived', 'Embarked_Q'): 30, ('Survived', 'Embarked_S'): 217, ('Survived', 'Pclass_1'): 136, ('Survived', 'Pclass_2'): 87, ('Survived', 'Pclass_3'): 119, ('Sex_female', 'Age_Child'): 84, ('Sex_female', 'Age_Adult'): 168, ('Sex_female', 'Embarked_C'): 73, ('Sex_female', 'Embarked_Q'): 36, ('Sex_female', 'Embarked_S'): 203, ('Sex_female', 'Pclass_1'): 94, ('Sex_female', 'Pclass_2'): 76, ('Sex_female', 'Pclass_3'): 144, ('Sex_male', 'Age_Child'): 120, ('Sex_male', 'Age_Adult'): 302, ('Sex_male', 'Age_Elderly'): 31, ('Sex_male', 'Embarked_C'): 95, ('Sex_male', 'Embarked_Q'): 41, ('Sex_male', 'Embarked_S'): 441, ('Sex_male', 'Pclass_1'): 122, ('Sex_male', 'Pclass_2'): 108, ('Sex_male', 'Pclass_3'): 347, ('Age_Child', 'Embarked_C'): 33, ('Age_Child', 'Embarked_S'): 159, ('Age_Child', 'Pclass_2'): 39, ('Age_Child', 'Pclass_3'): 141, ('Age_Adult', 'Embarked_C'): 86, ('Age_Adult', 'Embarked_S'): 370, ('Age_Adult', 'Pclass_1'): 136, ('Age_Adult', 'Pclass_2'): 127, ('Age_Adult', 'Pclass_3'): 207, ('Embarked_C', 'Pclass_1'): 85, ('Embarked_C', 'Pclass_3'): 66, ('Embarked_Q', 'Pclass_3'): 72, ('Embarked_S', 'Pclass_1'): 127, ('Embarked_S', 'Pclass_2'): 164, ('Embarked_S', 'Pclass_3'): 353, ('Survived', 'Sex_female', 'Age_Child'): 57, ('Survived', 'Sex_female', 'Age_Adult'): 132, ('Survived', 'Sex_female', 'Embarked_C'): 64, ('Survived', 'Sex_female', 'Embarked_S'): 140, ('Survived', 'Sex_female', 'Pclass_1'): 91, ('Survived', 'Sex_female', 'Pclass_2'): 70, ('Survived', 'Sex_female', 'Pclass_3'): 72, ('Survived', 'Sex_male', 'Age_Child'): 30, ('Survived', 'Sex_male', 'Age_Adult'): 59, ('Survived', 'Sex_male', 'Embarked_S'): 77, ('Survived', 'Sex_male', 'Pclass_1'): 45, ('Survived', 'Sex_male', 'Pclass_3'): 47, ('Survived', 'Age_Child', 'Embarked_S'): 59, ('Survived', 'Age_Child', 'Pclass_3'): 41, ('Survived', 'Age_Adult', 'Embarked_C'): 50, ('Survived', 'Age_Adult', 'Embarked_S'): 136, ('Survived', 'Age_Adult', 'Pclass_1'): 93, ('Survived', 'Age_Adult', 'Pclass_2'): 55, ('Survived', 'Age_Adult', 'Pclass_3'): 43, ('Survived', 'Embarked_C', 'Pclass_1'): 59, ('Survived', 'Embarked_S', 'Pclass_1'): 74, ('Survived', 'Embarked_S', 'Pclass_2'): 76, ('Survived', 'Embarked_S', 'Pclass_3'): 67, ('Sex_female', 'Age_Child', 'Embarked_S'): 56, ('Sex_female', 'Age_Child', 'Pclass_3'): 51, ('Sex_female', 'Age_Adult', 'Embarked_C'): 36, ('Sex_female', 'Age_Adult', 'Embarked_S'): 125, ('Sex_female', 'Age_Adult', 'Pclass_1'): 62, ('Sex_female', 'Age_Adult', 'Pclass_2'): 56, ('Sex_female', 'Age_Adult', 'Pclass_3'): 50, ('Sex_female', 'Embarked_C', 'Pclass_1'): 43, ('Sex_female', 'Embarked_Q', 'Pclass_3'): 33, ('Sex_female', 'Embarked_S', 'Pclass_1'): 48, ('Sex_female', 'Embarked_S', 'Pclass_2'): 67, ('Sex_female', 'Embarked_S', 'Pclass_3'): 88, ('Sex_male', 'Age_Child', 'Embarked_S'): 103, ('Sex_male', 'Age_Child', 'Pclass_3'): 90, ('Sex_male', 'Age_Adult', 'Embarked_C'): 50, ('Sex_male', 'Age_Adult', 'Embarked_S'): 245, ('Sex_male', 'Age_Adult', 'Pclass_1'): 74, ('Sex_male', 'Age_Adult', 'Pclass_2'): 71, ('Sex_male', 'Age_Adult', 'Pclass_3'): 157, ('Sex_male', 'Embarked_C', 'Pclass_1'): 42, ('Sex_male', 'Embarked_C', 'Pclass_3'): 43, ('Sex_male', 'Embarked_Q', 'Pclass_3'): 39, ('Sex_male', 'Embarked_S', 'Pclass_1'): 79, ('Sex_male', 'Embarked_S', 'Pclass_2'): 97, ('Sex_male', 'Embarked_S', 'Pclass_3'): 265, ('Age_Child', 'Embarked_S', 'Pclass_2'): 35, ('Age_Child', 'Embarked_S', 'Pclass_3'): 108, ('Age_Adult', 'Embarked_C', 'Pclass_1'): 55, ('Age_Adult', 'Embarked_S', 'Pclass_1'): 78, ('Age_Adult', 'Embarked_S', 'Pclass_2'): 115, ('Age_Adult', 'Embarked_S', 'Pclass_3'): 177, ('Survived', 'Sex_female', 'Age_Child', 'Embarked_S'): 35, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_C'): 34, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S'): 94, ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_1'): 60, ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_2'): 51, ('Survived', 'Sex_female', 'Embarked_C', 'Pclass_1'): 42, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_1'): 46, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_2'): 61, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_3'): 33, ('Survived', 'Sex_male', 'Age_Adult', 'Embarked_S'): 42, ('Survived', 'Sex_male', 'Age_Adult', 'Pclass_1'): 33, ('Survived', 'Sex_male', 'Embarked_S', 'Pclass_3'): 34, ('Survived', 'Age_Adult', 'Embarked_C', 'Pclass_1'): 41, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 50, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 50, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 36, ('Sex_female', 'Age_Child', 'Embarked_S', 'Pclass_3'): 32, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 31, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 51, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 43, ('Sex_male', 'Age_Child', 'Embarked_S', 'Pclass_3'): 76, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 47, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 64, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 134}\n",
      "k:  5\n",
      "{('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491, ('Survived', 'Sex_female'): 233, ('Survived', 'Sex_male'): 109, ('Survived', 'Age_Child'): 87, ('Survived', 'Age_Adult'): 191, ('Survived', 'Embarked_C'): 93, ('Survived', 'Embarked_Q'): 30, ('Survived', 'Embarked_S'): 217, ('Survived', 'Pclass_1'): 136, ('Survived', 'Pclass_2'): 87, ('Survived', 'Pclass_3'): 119, ('Sex_female', 'Age_Child'): 84, ('Sex_female', 'Age_Adult'): 168, ('Sex_female', 'Embarked_C'): 73, ('Sex_female', 'Embarked_Q'): 36, ('Sex_female', 'Embarked_S'): 203, ('Sex_female', 'Pclass_1'): 94, ('Sex_female', 'Pclass_2'): 76, ('Sex_female', 'Pclass_3'): 144, ('Sex_male', 'Age_Child'): 120, ('Sex_male', 'Age_Adult'): 302, ('Sex_male', 'Age_Elderly'): 31, ('Sex_male', 'Embarked_C'): 95, ('Sex_male', 'Embarked_Q'): 41, ('Sex_male', 'Embarked_S'): 441, ('Sex_male', 'Pclass_1'): 122, ('Sex_male', 'Pclass_2'): 108, ('Sex_male', 'Pclass_3'): 347, ('Age_Child', 'Embarked_C'): 33, ('Age_Child', 'Embarked_S'): 159, ('Age_Child', 'Pclass_2'): 39, ('Age_Child', 'Pclass_3'): 141, ('Age_Adult', 'Embarked_C'): 86, ('Age_Adult', 'Embarked_S'): 370, ('Age_Adult', 'Pclass_1'): 136, ('Age_Adult', 'Pclass_2'): 127, ('Age_Adult', 'Pclass_3'): 207, ('Embarked_C', 'Pclass_1'): 85, ('Embarked_C', 'Pclass_3'): 66, ('Embarked_Q', 'Pclass_3'): 72, ('Embarked_S', 'Pclass_1'): 127, ('Embarked_S', 'Pclass_2'): 164, ('Embarked_S', 'Pclass_3'): 353, ('Survived', 'Sex_female', 'Age_Child'): 57, ('Survived', 'Sex_female', 'Age_Adult'): 132, ('Survived', 'Sex_female', 'Embarked_C'): 64, ('Survived', 'Sex_female', 'Embarked_S'): 140, ('Survived', 'Sex_female', 'Pclass_1'): 91, ('Survived', 'Sex_female', 'Pclass_2'): 70, ('Survived', 'Sex_female', 'Pclass_3'): 72, ('Survived', 'Sex_male', 'Age_Child'): 30, ('Survived', 'Sex_male', 'Age_Adult'): 59, ('Survived', 'Sex_male', 'Embarked_S'): 77, ('Survived', 'Sex_male', 'Pclass_1'): 45, ('Survived', 'Sex_male', 'Pclass_3'): 47, ('Survived', 'Age_Child', 'Embarked_S'): 59, ('Survived', 'Age_Child', 'Pclass_3'): 41, ('Survived', 'Age_Adult', 'Embarked_C'): 50, ('Survived', 'Age_Adult', 'Embarked_S'): 136, ('Survived', 'Age_Adult', 'Pclass_1'): 93, ('Survived', 'Age_Adult', 'Pclass_2'): 55, ('Survived', 'Age_Adult', 'Pclass_3'): 43, ('Survived', 'Embarked_C', 'Pclass_1'): 59, ('Survived', 'Embarked_S', 'Pclass_1'): 74, ('Survived', 'Embarked_S', 'Pclass_2'): 76, ('Survived', 'Embarked_S', 'Pclass_3'): 67, ('Sex_female', 'Age_Child', 'Embarked_S'): 56, ('Sex_female', 'Age_Child', 'Pclass_3'): 51, ('Sex_female', 'Age_Adult', 'Embarked_C'): 36, ('Sex_female', 'Age_Adult', 'Embarked_S'): 125, ('Sex_female', 'Age_Adult', 'Pclass_1'): 62, ('Sex_female', 'Age_Adult', 'Pclass_2'): 56, ('Sex_female', 'Age_Adult', 'Pclass_3'): 50, ('Sex_female', 'Embarked_C', 'Pclass_1'): 43, ('Sex_female', 'Embarked_Q', 'Pclass_3'): 33, ('Sex_female', 'Embarked_S', 'Pclass_1'): 48, ('Sex_female', 'Embarked_S', 'Pclass_2'): 67, ('Sex_female', 'Embarked_S', 'Pclass_3'): 88, ('Sex_male', 'Age_Child', 'Embarked_S'): 103, ('Sex_male', 'Age_Child', 'Pclass_3'): 90, ('Sex_male', 'Age_Adult', 'Embarked_C'): 50, ('Sex_male', 'Age_Adult', 'Embarked_S'): 245, ('Sex_male', 'Age_Adult', 'Pclass_1'): 74, ('Sex_male', 'Age_Adult', 'Pclass_2'): 71, ('Sex_male', 'Age_Adult', 'Pclass_3'): 157, ('Sex_male', 'Embarked_C', 'Pclass_1'): 42, ('Sex_male', 'Embarked_C', 'Pclass_3'): 43, ('Sex_male', 'Embarked_Q', 'Pclass_3'): 39, ('Sex_male', 'Embarked_S', 'Pclass_1'): 79, ('Sex_male', 'Embarked_S', 'Pclass_2'): 97, ('Sex_male', 'Embarked_S', 'Pclass_3'): 265, ('Age_Child', 'Embarked_S', 'Pclass_2'): 35, ('Age_Child', 'Embarked_S', 'Pclass_3'): 108, ('Age_Adult', 'Embarked_C', 'Pclass_1'): 55, ('Age_Adult', 'Embarked_S', 'Pclass_1'): 78, ('Age_Adult', 'Embarked_S', 'Pclass_2'): 115, ('Age_Adult', 'Embarked_S', 'Pclass_3'): 177, ('Survived', 'Sex_female', 'Age_Child', 'Embarked_S'): 35, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_C'): 34, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S'): 94, ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_1'): 60, ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_2'): 51, ('Survived', 'Sex_female', 'Embarked_C', 'Pclass_1'): 42, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_1'): 46, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_2'): 61, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_3'): 33, ('Survived', 'Sex_male', 'Age_Adult', 'Embarked_S'): 42, ('Survived', 'Sex_male', 'Age_Adult', 'Pclass_1'): 33, ('Survived', 'Sex_male', 'Embarked_S', 'Pclass_3'): 34, ('Survived', 'Age_Adult', 'Embarked_C', 'Pclass_1'): 41, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 50, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 50, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 36, ('Sex_female', 'Age_Child', 'Embarked_S', 'Pclass_3'): 32, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 31, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 51, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 43, ('Sex_male', 'Age_Child', 'Embarked_S', 'Pclass_3'): 76, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 47, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 64, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 134, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 30, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 46}\n",
      "k:  6\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Child')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Embarked_C')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Age_Child')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Age_Child')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Child')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_C')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Embarked_C')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Child')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Child')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Child', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_C')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_C')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_C')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_2')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Embarked_C')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_C')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_C', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_2')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_3')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_3')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_male', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_male', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_male', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_male', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_male')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Sex_male', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_male', 'Pclass_3')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_3')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_C')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_C')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_C', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_2')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_2')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_3')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_3')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_3')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_1')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_1')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_1')\n",
      "Survived ('Survived', 'Sex_female')\n",
      "Survived ('Survived', 'Age_Adult')\n",
      "Survived ('Survived', 'Embarked_S')\n",
      "Survived ('Survived', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Pclass_2')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Age_Adult', 'Pclass_2')\n",
      "Survived ('Survived', 'Embarked_S', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S')\n",
      "Survived ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_2')\n",
      "Survived ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_2')\n",
      "Survived ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_2')\n"
     ]
    }
   ],
   "source": [
    "# Run the apriori algorithm\n",
    "combined_freq_itemsets, rules = my_apriori(train_titanic_df, 30, 0.4, target='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined frequent itemsets:  {('Survived',): 342, ('Sex_female',): 314, ('Sex_male',): 577, ('Age_Child',): 204, ('Age_Adult',): 470, ('Age_Elderly',): 40, ('Embarked_C',): 168, ('Embarked_Q',): 77, ('Embarked_S',): 644, ('Pclass_1',): 216, ('Pclass_2',): 184, ('Pclass_3',): 491, ('Survived', 'Sex_female'): 233, ('Survived', 'Sex_male'): 109, ('Survived', 'Age_Child'): 87, ('Survived', 'Age_Adult'): 191, ('Survived', 'Embarked_C'): 93, ('Survived', 'Embarked_Q'): 30, ('Survived', 'Embarked_S'): 217, ('Survived', 'Pclass_1'): 136, ('Survived', 'Pclass_2'): 87, ('Survived', 'Pclass_3'): 119, ('Sex_female', 'Age_Child'): 84, ('Sex_female', 'Age_Adult'): 168, ('Sex_female', 'Embarked_C'): 73, ('Sex_female', 'Embarked_Q'): 36, ('Sex_female', 'Embarked_S'): 203, ('Sex_female', 'Pclass_1'): 94, ('Sex_female', 'Pclass_2'): 76, ('Sex_female', 'Pclass_3'): 144, ('Sex_male', 'Age_Child'): 120, ('Sex_male', 'Age_Adult'): 302, ('Sex_male', 'Age_Elderly'): 31, ('Sex_male', 'Embarked_C'): 95, ('Sex_male', 'Embarked_Q'): 41, ('Sex_male', 'Embarked_S'): 441, ('Sex_male', 'Pclass_1'): 122, ('Sex_male', 'Pclass_2'): 108, ('Sex_male', 'Pclass_3'): 347, ('Age_Child', 'Embarked_C'): 33, ('Age_Child', 'Embarked_S'): 159, ('Age_Child', 'Pclass_2'): 39, ('Age_Child', 'Pclass_3'): 141, ('Age_Adult', 'Embarked_C'): 86, ('Age_Adult', 'Embarked_S'): 370, ('Age_Adult', 'Pclass_1'): 136, ('Age_Adult', 'Pclass_2'): 127, ('Age_Adult', 'Pclass_3'): 207, ('Embarked_C', 'Pclass_1'): 85, ('Embarked_C', 'Pclass_3'): 66, ('Embarked_Q', 'Pclass_3'): 72, ('Embarked_S', 'Pclass_1'): 127, ('Embarked_S', 'Pclass_2'): 164, ('Embarked_S', 'Pclass_3'): 353, ('Survived', 'Sex_female', 'Age_Child'): 57, ('Survived', 'Sex_female', 'Age_Adult'): 132, ('Survived', 'Sex_female', 'Embarked_C'): 64, ('Survived', 'Sex_female', 'Embarked_S'): 140, ('Survived', 'Sex_female', 'Pclass_1'): 91, ('Survived', 'Sex_female', 'Pclass_2'): 70, ('Survived', 'Sex_female', 'Pclass_3'): 72, ('Survived', 'Sex_male', 'Age_Child'): 30, ('Survived', 'Sex_male', 'Age_Adult'): 59, ('Survived', 'Sex_male', 'Embarked_S'): 77, ('Survived', 'Sex_male', 'Pclass_1'): 45, ('Survived', 'Sex_male', 'Pclass_3'): 47, ('Survived', 'Age_Child', 'Embarked_S'): 59, ('Survived', 'Age_Child', 'Pclass_3'): 41, ('Survived', 'Age_Adult', 'Embarked_C'): 50, ('Survived', 'Age_Adult', 'Embarked_S'): 136, ('Survived', 'Age_Adult', 'Pclass_1'): 93, ('Survived', 'Age_Adult', 'Pclass_2'): 55, ('Survived', 'Age_Adult', 'Pclass_3'): 43, ('Survived', 'Embarked_C', 'Pclass_1'): 59, ('Survived', 'Embarked_S', 'Pclass_1'): 74, ('Survived', 'Embarked_S', 'Pclass_2'): 76, ('Survived', 'Embarked_S', 'Pclass_3'): 67, ('Sex_female', 'Age_Child', 'Embarked_S'): 56, ('Sex_female', 'Age_Child', 'Pclass_3'): 51, ('Sex_female', 'Age_Adult', 'Embarked_C'): 36, ('Sex_female', 'Age_Adult', 'Embarked_S'): 125, ('Sex_female', 'Age_Adult', 'Pclass_1'): 62, ('Sex_female', 'Age_Adult', 'Pclass_2'): 56, ('Sex_female', 'Age_Adult', 'Pclass_3'): 50, ('Sex_female', 'Embarked_C', 'Pclass_1'): 43, ('Sex_female', 'Embarked_Q', 'Pclass_3'): 33, ('Sex_female', 'Embarked_S', 'Pclass_1'): 48, ('Sex_female', 'Embarked_S', 'Pclass_2'): 67, ('Sex_female', 'Embarked_S', 'Pclass_3'): 88, ('Sex_male', 'Age_Child', 'Embarked_S'): 103, ('Sex_male', 'Age_Child', 'Pclass_3'): 90, ('Sex_male', 'Age_Adult', 'Embarked_C'): 50, ('Sex_male', 'Age_Adult', 'Embarked_S'): 245, ('Sex_male', 'Age_Adult', 'Pclass_1'): 74, ('Sex_male', 'Age_Adult', 'Pclass_2'): 71, ('Sex_male', 'Age_Adult', 'Pclass_3'): 157, ('Sex_male', 'Embarked_C', 'Pclass_1'): 42, ('Sex_male', 'Embarked_C', 'Pclass_3'): 43, ('Sex_male', 'Embarked_Q', 'Pclass_3'): 39, ('Sex_male', 'Embarked_S', 'Pclass_1'): 79, ('Sex_male', 'Embarked_S', 'Pclass_2'): 97, ('Sex_male', 'Embarked_S', 'Pclass_3'): 265, ('Age_Child', 'Embarked_S', 'Pclass_2'): 35, ('Age_Child', 'Embarked_S', 'Pclass_3'): 108, ('Age_Adult', 'Embarked_C', 'Pclass_1'): 55, ('Age_Adult', 'Embarked_S', 'Pclass_1'): 78, ('Age_Adult', 'Embarked_S', 'Pclass_2'): 115, ('Age_Adult', 'Embarked_S', 'Pclass_3'): 177, ('Survived', 'Sex_female', 'Age_Child', 'Embarked_S'): 35, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_C'): 34, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S'): 94, ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_1'): 60, ('Survived', 'Sex_female', 'Age_Adult', 'Pclass_2'): 51, ('Survived', 'Sex_female', 'Embarked_C', 'Pclass_1'): 42, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_1'): 46, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_2'): 61, ('Survived', 'Sex_female', 'Embarked_S', 'Pclass_3'): 33, ('Survived', 'Sex_male', 'Age_Adult', 'Embarked_S'): 42, ('Survived', 'Sex_male', 'Age_Adult', 'Pclass_1'): 33, ('Survived', 'Sex_male', 'Embarked_S', 'Pclass_3'): 34, ('Survived', 'Age_Adult', 'Embarked_C', 'Pclass_1'): 41, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 50, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 50, ('Survived', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 36, ('Sex_female', 'Age_Child', 'Embarked_S', 'Pclass_3'): 32, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 31, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 51, ('Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 43, ('Sex_male', 'Age_Child', 'Embarked_S', 'Pclass_3'): 76, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 47, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 64, ('Sex_male', 'Age_Adult', 'Embarked_S', 'Pclass_3'): 134, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_1'): 30, ('Survived', 'Sex_female', 'Age_Adult', 'Embarked_S', 'Pclass_2'): 46}\n"
     ]
    }
   ],
   "source": [
    "print('combined frequent itemsets: ', combined_freq_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule  1 : antecedent -> consequent:  ['Sex_female'] ->  ['Survived'] confidence:  0.445859872611465\n",
      "Rule  2 : antecedent -> consequent:  ['Pclass_1'] ->  ['Survived'] confidence:  0.4305555555555556\n",
      "Rule  3 : antecedent -> consequent:  ['Pclass_2'] ->  ['Survived'] confidence:  0.41304347826086957\n",
      "Rule  4 : antecedent -> consequent:  ['Sex_female', 'Age_Child'] ->  ['Survived'] confidence:  0.4166666666666667\n",
      "Rule  5 : antecedent -> consequent:  ['Sex_female', 'Embarked_C'] ->  ['Survived'] confidence:  0.5753424657534246\n",
      "Rule  6 : antecedent -> consequent:  ['Sex_female', 'Age_Adult'] ->  ['Survived'] confidence:  0.5595238095238095\n",
      "Rule  7 : antecedent -> consequent:  ['Sex_female', 'Embarked_S'] ->  ['Survived'] confidence:  0.4630541871921182\n",
      "Rule  8 : antecedent -> consequent:  ['Sex_female', 'Pclass_1'] ->  ['Survived'] confidence:  0.48936170212765956\n",
      "Rule  9 : antecedent -> consequent:  ['Age_Adult', 'Pclass_1'] ->  ['Survived'] confidence:  0.4411764705882353\n",
      "Rule  10 : antecedent -> consequent:  ['Sex_female', 'Pclass_2'] ->  ['Survived'] confidence:  0.6052631578947368\n",
      "Rule  11 : antecedent -> consequent:  ['Age_Adult', 'Pclass_2'] ->  ['Survived'] confidence:  0.4015748031496063\n",
      "Rule  12 : antecedent -> consequent:  ['Embarked_C', 'Pclass_1'] ->  ['Survived'] confidence:  0.4823529411764706\n",
      "Rule  13 : antecedent -> consequent:  ['Age_Adult', 'Embarked_C'] ->  ['Survived'] confidence:  0.47674418604651164\n",
      "Rule  14 : antecedent -> consequent:  ['Sex_female', 'Age_Adult', 'Pclass_1'] ->  ['Survived'] confidence:  0.4838709677419355\n",
      "Rule  15 : antecedent -> consequent:  ['Sex_female', 'Embarked_S', 'Pclass_1'] ->  ['Survived'] confidence:  0.625\n",
      "Rule  16 : antecedent -> consequent:  ['Sex_female', 'Age_Adult', 'Pclass_2'] ->  ['Survived'] confidence:  0.8214285714285714\n",
      "Rule  17 : antecedent -> consequent:  ['Sex_female', 'Embarked_S', 'Pclass_2'] ->  ['Survived'] confidence:  0.6865671641791045\n",
      "Rule  18 : antecedent -> consequent:  ['Age_Adult', 'Embarked_S', 'Pclass_2'] ->  ['Survived'] confidence:  0.4\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for key, item in rules.items():\n",
    "    for i in range(1, len(key)):\n",
    "        antecedent = key[:i]\n",
    "        consequent = key[i:]\n",
    "        print('Rule ', index, ': antecedent -> consequent: ', list(sum(antecedent, ())), '-> ', list(sum(consequent, ())), 'confidence: ', item)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
